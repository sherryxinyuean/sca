{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run SSA and weighted PCA on center-out (red and yellow, long delay) reaching data. Plot projections in pca and ssa dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "from scipy import io\n",
    "import seaborn as sns\n",
    "import time\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# from ssa_functions import fit_ssa, get_sample_weights, weighted_pca, weighted_rrr\n",
    "import sys\n",
    "sys.path.append('/Users/sherryan/glaserlab/sca_analysis_parent/ssa')\n",
    "\n",
    "from ssa import fit_ssa, weighted_pca\n",
    "from ssa.util import get_sample_weights\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sys.path.append('/Users/sherryan/glaserlab/sca_analysis_parent/dPCA')\n",
    "from dPCA import dPCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc('font', size=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which monkey are we working with?\n",
    "monkName = 'Balboa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder with rates\n",
    "load_folder='/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/'\n",
    "\n",
    "# load data\n",
    "data=io.loadmat(load_folder + monkName + '_outAndBack_redYellowConds_rawRates.mat')\n",
    "\n",
    "# pull out the psths\n",
    "# data is a C x N x T tensor \n",
    "data_array=data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downsample data (using a factor of 10 here)\n",
    "data_downsamp=data_array[:,:,np.arange(0,data_array.shape[2],10)]\n",
    "\n",
    "# pull out some useful numbers\n",
    "numConds,numN,trlDur = np.shape(data_downsamp)\n",
    "\n",
    "#Concatenate all the conditions (so the matrix is size N x TC instead of C x N x T)\n",
    "data_concat=data_downsamp.swapaxes(0,1).reshape([data_downsamp.shape[1],data_downsamp.shape[0]*data_downsamp.shape[2]])\n",
    "\n",
    "#fr range\n",
    "fr_range=np.ptp(data_concat,axis=1)[:,None]\n",
    "\n",
    "# make a time mask\n",
    "timeMask = np.tile(np.arange(trlDur),(1,numConds)).T.flatten()\n",
    "\n",
    "# define the times we want to use for ssa/pca\n",
    "# target on: 20\n",
    "# move on:   77\n",
    "# return:    200\n",
    "trainTimes = np.arange(20,230)\n",
    "\n",
    "# define a 'training mask' for convenience \n",
    "trainMask = np.in1d(timeMask,trainTimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subtract cross-condition mean\n",
    "data_scm=data_downsamp-np.mean(data_downsamp,axis=0)[None,:,:]\n",
    "\n",
    "#Concatenate all the conditions (so the matrix is size N x TC instead of C x N x T)\n",
    "data_scm_concat=data_scm.swapaxes(0,1).reshape([data_downsamp.shape[1],data_downsamp.shape[0]*data_downsamp.shape[2]])\n",
    "\n",
    "#Soft normalize (divide each neuron by its fr range + 5)\n",
    "data_scm_norm=data_scm_concat/(fr_range+5)\n",
    "\n",
    "# # mean-center the data (not needed in subtracted cross-condition mean)\n",
    "# dMean = np.tile(np.mean(data_scm_norm,axis=1)[:,np.newaxis],(1,data_scm_norm.shape[1]))\n",
    "# data_mc = data_scm_norm - dMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_data=np.copy(data_scm_norm.T) \n",
    "# how much to weight each timestep (used by)\n",
    "sample_weights=get_sample_weights(fit_data)\n",
    "fit_data_weighted = (fit_data * sample_weights)\n",
    "fit_data_weighted.shape #CT*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nst_norm_w = fit_data_weighted.T.reshape([data_downsamp.shape[1],data_downsamp.shape[0], data_downsamp.shape[2]]) # data is a N x C x T tensor \n",
    "data_nst_norm_w.shape\n",
    "\n",
    "data_nst_norm = fit_data.T.reshape([data_downsamp.shape[1],data_downsamp.shape[0], data_downsamp.shape[2]]) # data is a N x C x T tensor \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainT = np.arange(20,230)\n",
    "trialT = np.arange(trlDur)\n",
    "dpcaMask = np.in1d(trialT, trainT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_est = 8\n",
    "dpca = dPCA.dPCA(labels='st',n_components=R_est)\n",
    "dpca.protect = ['t']\n",
    "dpca.fit(data_nst_norm_w[:,:,dpcaMask])\n",
    "dpca_latents = dpca.transform(data_nst_norm)\n",
    "\n",
    "T = data_nst_norm.shape[2]\n",
    "S = data_nst_norm.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpca_order_var=np.argsort(-np.array(dpca.explained_variance_ratio_['st']))\n",
    "dpca_order_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "dpca_proj = dpca_latents['st'][dpca_order_var[:8]].transpose(2,1,0)\n",
    "R_est = 8\n",
    "\n",
    "# g_cMap  = ['#00d01e', '#00ba22', '#00a426', '#008e2a', '#00782e', '#006232', '#004c36', '#00363a']\n",
    "# g_cMap  = ['#e8a048', '#d48b3f', '#c07737', '#ac632e', '#984e26', '#843a1d', '#702615', '#5c120d']\n",
    "dpca_cMap  = ['#0bffe0', '#0ae2c7', '#0ac6af', '#0aaa97', '#0a8d7e', '#0a7166', '#0a554e', '#0a3936']\n",
    "\n",
    "# define some useful time points\n",
    "tgt_idx=20\n",
    "move_idx=77\n",
    "ret_idx=200\n",
    "# range for y axis\n",
    "yRange = [-1.8,1.8]\n",
    "fig = make_subplots(rows=R_est,cols = 1,shared_xaxes = True,vertical_spacing = 0)\n",
    "\n",
    "for ii in range(R_est):\n",
    "\n",
    "    for jj in range(numConds):\n",
    "        latTrace = go.Scatter(y = dpca_proj[:,jj,ii], line = go.scatter.Line(color = dpca_cMap[jj],width = 1),showlegend = False)\n",
    "        fig.add_trace(latTrace,row = ii+1,col=1)\n",
    "        if ii == (R_est-1):\n",
    "            fig.add_vline(x = tgt_idx,row = ii+1,col = 1, line_color = 'black')\n",
    "            fig.add_vline(x = move_idx,row = ii+1,col = 1, line_color = 'black')\n",
    "            fig.add_vline(x = ret_idx,row = ii+1,col = 1, line_color = 'black')\n",
    "\n",
    "            #\n",
    "    # add a vertical line for scale\n",
    "    scaleLine = go.Scatter(x = [-5, -5],y = [-0.4,0.4],showlegend = False,mode = 'lines',\n",
    "                            line = go.scatter.Line(color = 'black',width = 3))\n",
    "    fig.add_trace(scaleLine,row = ii+1,col = 1)\n",
    "\n",
    "\n",
    "fig.update_layout(height = 1000,width =500,title = 'dPCA ' + monkName,title_font_color = 'black',\n",
    "                  paper_bgcolor = 'white',\n",
    "                  plot_bgcolor = 'white')\n",
    "fig.update_yaxes(showgrid = False,zeroline = False,visible = False,range = yRange)\n",
    "fig.update_xaxes(color = 'black',showgrid = False,zeroline = False,visible = False)\n",
    "fig.update_xaxes(color = 'black',showgrid = False,zeroline = False,\n",
    "                 ticks = 'outside',tickvals = [0,50],ticktext = ['0','500'],visible = True,row = R_est,col = 1)\n",
    "\n",
    "\n",
    "# save\n",
    "figDir = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/'\n",
    "fig.write_image(figDir + monkName + 'dpca_' + str(R_est) + 'dims.pdf')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colorIdx = np.arange(0.55,1,0.4/8)\n",
    "# dpca_cMap = sns.cubehelix_palette(start = 0.1,rot = 0.6,dark = 0.15, light = 0.8,as_cmap = True,gamma = 0.5)\n",
    "# dpca_cMap = dpca_cMap(colorIdx)\n",
    "\n",
    "# #Get indices of each trial\n",
    "# T=data_downsamp.shape[2] #Length of time per condition\n",
    "# trs=np.arange(0,8)\n",
    "# t_idxs=[np.arange(T*tr,T*(tr+1)) for tr in trs]\n",
    "\n",
    "# # define some useful time points\n",
    "# tgt_idx=20\n",
    "# move_idx=77\n",
    "# ret_idx=200\n",
    "\n",
    "# fig,ax=plt.subplots(R_est,1,figsize=(10,15))\n",
    "# for i in range(R_est):\n",
    "#     for j in range(len(trs)):\n",
    "\n",
    "#         ax[i].plot(dpca_latents['st'][dpca_order_var[i],j] - np.mean(dpca_latents['st'][dpca_order_var[i]]) ,linewidth=2.25,color=dpca_cMap[j,:])\n",
    "        \n",
    "#         ax[i].plot([tgt_idx,tgt_idx],[-1.7,1.7],'gray',linewidth=.5)\n",
    "#         ax[i].plot([move_idx,move_idx],[-2,2],'k',linewidth=.5)\n",
    "#         ax[i].plot([ret_idx,ret_idx],[-2,2],'k',linewidth=.5)\n",
    "#         ax[i].plot([0,T],[0,0],'k--')\n",
    "\n",
    "#         ax[i].set_xlim([0,T+1])\n",
    "#         # ax[i].set_ylim([-2.5, 2.5])\n",
    "\n",
    "#         if i<R_est-1:\n",
    "#             ax[i].set_xticks([])\n",
    "#         else:\n",
    "#             ax[i].set_xlabel('Time (10ms bins)')\n",
    "            \n",
    "#         ax[i].set_yticks([])\n",
    "#         ax[i].set_ylabel('Dim. '+str(i+1))\n",
    "\n",
    "#     ax[0].set_title('dPCA Projections')\n",
    "\n",
    "# # save\n",
    "# # figDir = '/Users/sherryan//sca_analysis_parent/sca_analysis/original_fit/'\n",
    "# # plt.savefig(figDir + monkName + '_dpcaProj_original_dim' + str(R_est) + '.pdf',dpi = 'figure')glaserlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(T)\n",
    "\n",
    "plt.figure(figsize=(16,7))\n",
    "plt.subplot(131)\n",
    "\n",
    "for s in range(S):\n",
    "    plt.plot(time,dpca_latents['t'][0,s])\n",
    "\n",
    "plt.title('1st time component')\n",
    "    \n",
    "plt.subplot(132)\n",
    "\n",
    "for s in range(S):\n",
    "    plt.plot(time,dpca_latents['s'][1,s])\n",
    "    \n",
    "plt.title('1st stimulus component')\n",
    "    \n",
    "plt.subplot(133)\n",
    "\n",
    "for s in range(S):\n",
    "    plt.plot(time,dpca_latents['st'][0,s])\n",
    "    \n",
    "plt.title('1st mixing component')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit SCA and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_data=np.copy(data_scm_norm.T) \n",
    "# how much to weight each timestep (used by)\n",
    "sample_weights=get_sample_weights(fit_data)\n",
    "\n",
    "# number of dimensions to find\n",
    "R_est= 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_data.shape\n",
    "saveDir = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/'\n",
    "io.savemat(saveDir+ monkName + '_' + 'proc_neural_data.mat'\n",
    "           , {'neuron_proc_activity': fit_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, latent, y_pred, losses = fit_ssa(X=fit_data[trainMask,:],R=R_est,sample_weight=sample_weights[trainMask],orth = False)\n",
    "#Get the low dimensional representation\n",
    "ssa_latent=fit_data@model.fc1.weight.detach().numpy().T+model.fc1.bias.detach().numpy()\n",
    "\n",
    "#Plot the loss over all iterations\n",
    "plt.figure()\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Training Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the loss over the last 100 iterations (to see if it has truly hit a plateau)\n",
    "plt.figure()\n",
    "plt.plot(losses[-100:-1])\n",
    "plt.xlabel('Training Epoch')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot VT@V to see orthogonality of dimensions\n",
    "product=model.fc2.weight.detach().numpy().T@model.fc2.weight.detach().numpy()\n",
    "plt.imshow(product,clim=[-1,1],cmap='RdBu')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Amount of squared activity each dimension explains in SSA\n",
    "V_est_ssa=model.fc2.weight.detach().numpy()\n",
    "infs_ssa=[np.sum((ssa_latent[:,i:i+1]@V_est_ssa[:,i:i+1].T)**2,axis=1) for i in range(R_est)]\n",
    "\n",
    "cum_array_ssa_var=[np.sum(infs_ssa[i]) for i in range(R_est)]\n",
    "\n",
    "#Order dimensions\n",
    "ssa_order_var=np.argsort(-np.array(cum_array_ssa_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save original SCA model weights\n",
    "saveDir = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/original_fit/'\n",
    "io.savemat(saveDir+ monkName + '_' + 'sca_original_dim' + str(R_est) + '.mat'\n",
    "           , {'U': model.fc1.weight.detach().numpy().T, 'V': model.fc2.weight.detach().numpy().T\n",
    "           , 'data': fit_data, 'U_bias': model.fc1.bias.detach().numpy(),'V_bias': model.fc2.bias.detach().numpy()\n",
    "           , 'predictions':y_pred,'latents':ssa_latent})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run weighted PCA for comparison\n",
    "U_est_pca,V_est_pca = weighted_pca(fit_data[trainMask,:],R_est,sample_weights[trainMask])\n",
    "pca_latent = fit_data@U_est_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save original PCA model weights\n",
    "saveDir = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/original_fit/'\n",
    "io.savemat(saveDir+ monkName + '_' + 'pca_original_dim' + str(R_est) + '.mat'\n",
    "           , {'U': U_est_pca, 'V': V_est_pca\n",
    "           , 'data': fit_data, 'latents': pca_latent})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Amount of squared activity each dimension explains in PCA\n",
    "infs_pca=[np.sum((pca_latent[:,i:i+1]@V_est_pca[i:i+1,:])**2,axis=1) for i in range(R_est)]\n",
    "\n",
    "#Amount of squared activity each dimension explains in SSA\n",
    "V_est_ssa=model.fc2.weight.detach().numpy()\n",
    "infs_ssa=[np.sum((ssa_latent[:,i:i+1]@V_est_ssa[:,i:i+1].T)**2,axis=1) for i in range(R_est)]\n",
    "\n",
    "cum_array_pca_var=[np.sum(infs_pca[i]) for i in range(R_est)]\n",
    "cum_array_ssa_var=[np.sum(infs_ssa[i]) for i in range(R_est)]\n",
    "\n",
    "#Order dimensions\n",
    "pca_order_var=np.argsort(-np.array(cum_array_pca_var))\n",
    "ssa_order_var=np.argsort(-np.array(cum_array_ssa_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "for i in range(R_est):\n",
    "    \n",
    "  \n",
    "    # Plot SSA results\n",
    "    plt.subplot(R_est,2,2*i+1)\n",
    "    plt.plot(ssa_latent[:,ssa_order_var[i]])\n",
    "    \n",
    "    plt.yticks([])    \n",
    "    if i<R_est-1:\n",
    "        plt.xticks([])\n",
    "    else:\n",
    "        plt.xlabel('Time')\n",
    "\n",
    "    # Plot PCA results\n",
    "    plt.subplot(R_est,2,2*i+2)\n",
    "    plt.plot(pca_latent[:,pca_order_var[i]])\n",
    "    \n",
    "    plt.yticks([])\n",
    "    if i<R_est-1:\n",
    "        plt.xticks([])\n",
    "    else:\n",
    "        plt.xlabel('Time')        \n",
    "\n",
    "\n",
    "plt.subplot(R_est,2,1)\n",
    "plt.title('SCA LowD Projections')\n",
    "\n",
    "plt.subplot(R_est,2,2)\n",
    "plt.title('PCA LowD Projections')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraction of colormap to use\n",
    "colorIdx = np.arange(0.55,1,0.4/8)\n",
    "\n",
    "# define ssa colors\n",
    "ssa_cMap = sns.cubehelix_palette(start = 0.1,rot = 0.6,dark = 0.15, light = 0.8,as_cmap = True,gamma = 1.1)\n",
    "ssa_cMap = ssa_cMap(colorIdx)\n",
    "\n",
    "# define pca colors\n",
    "pca_cMap = sns.cubehelix_palette(start = 0.1,rot = 0.6,dark = 0.15, light = 0.8,as_cmap = True,gamma = 0.7,hue = 0.3)\n",
    "pca_cMap = pca_cMap(colorIdx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Get indices of each trial\n",
    "T=data_downsamp.shape[2] #Length of time per condition\n",
    "trs=np.arange(0,8)\n",
    "t_idxs=[np.arange(T*tr,T*(tr+1)) for tr in trs]\n",
    "\n",
    "# define some useful time points\n",
    "tgt_idx=20\n",
    "move_idx=77\n",
    "ret_idx=200\n",
    "\n",
    "# change color of axis labels so we can see them in the pdf\n",
    "plt.rcParams['text.color'] = 'k'\n",
    "plt.rcParams['xtick.color'] = 'k'\n",
    "plt.rcParams['ytick.color'] = 'k'\n",
    "plt.rcParams['axes.labelcolor'] = 'k'\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(R_est,1,figsize=(10,15))\n",
    "for i in range(R_est):\n",
    "    for j in range(len(trs)):\n",
    "\n",
    "        ax[i].plot(pca_latent[:,pca_order_var[i]][t_idxs[j]] - np.mean(pca_latent[:,pca_order_var[i]]),linewidth=2.25,color=pca_cMap[j,:])\n",
    "        \n",
    "        ax[i].plot([tgt_idx,tgt_idx],[-1.7,1.7],'gray',linewidth=.5)\n",
    "        ax[i].plot([move_idx,move_idx],[-2,2],'k',linewidth=.5)\n",
    "        ax[i].plot([ret_idx,ret_idx],[-2,2],'k',linewidth=.5)\n",
    "\n",
    "        ax[i].set_xlim([0,T+1])\n",
    "        ax[i].set_ylim([-2.5, 2.5])\n",
    "        ax[i].plot([0,T],[0,0],'k--')\n",
    "        if i<R_est-1:\n",
    "            ax[i].set_xticks([])\n",
    "        else:\n",
    "            ax[i].set_xlabel('Time (10ms bins)')\n",
    "            \n",
    "        ax[i].set_yticks([])\n",
    "        ax[i].set_ylabel('Dim. '+str(i+1))\n",
    "\n",
    "    ax[0].set_title('PCA Projections')\n",
    "\n",
    "# # save figure\n",
    "\n",
    "# save directory\n",
    "figDir = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/original_fit/'\n",
    "\n",
    "# save\n",
    "plt.savefig(figDir + monkName + '_pcaProj_original_dim' + str(R_est) + '.pdf',dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get indices of each trial\n",
    "T=data_downsamp.shape[2] #Length of time per condition\n",
    "trs=np.arange(0,8)\n",
    "t_idxs=[np.arange(T*tr,T*(tr+1)) for tr in trs]\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(R_est,1,figsize=(10,15))\n",
    "for i in range(R_est):\n",
    "    for j in range(len(trs)):\n",
    "\n",
    "        ax[i].plot(ssa_latent[:,ssa_order_var[i]][t_idxs[j]] - np.mean(ssa_latent[:,ssa_order_var[i]]),linewidth=2.25,color=ssa_cMap[j,:])\n",
    "        \n",
    "        ax[i].plot([tgt_idx,tgt_idx],[-1.7,1.7],'gray',linewidth=.5)\n",
    "        ax[i].plot([move_idx,move_idx],[-2,2],'k',linewidth=.5)\n",
    "        ax[i].plot([ret_idx,ret_idx],[-2,2],'k',linewidth=.5)\n",
    "        ax[i].plot([0,T],[0,0],'k--')\n",
    "\n",
    "        ax[i].set_xlim([0,T+1])\n",
    "        ax[i].set_ylim([-2.5, 2.5])\n",
    "\n",
    "        if i<R_est-1:\n",
    "            ax[i].set_xticks([])\n",
    "        else:\n",
    "            ax[i].set_xlabel('Time (10ms bins)')\n",
    "            \n",
    "        ax[i].set_yticks([])\n",
    "        ax[i].set_ylabel('Dim. '+str(i+1))\n",
    "\n",
    "    ax[0].set_title('SCA Projections')\n",
    "\n",
    "# save\n",
    "# plt.savefig(figDir + monkName + '_scaProj_original_dim' + str(R_est) + '.pdf',dpi = 'figure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA/SCA consistency in sub-sampled neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_est = 8\n",
    "load_folder='/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/original_fit/'\n",
    "data=io.loadmat(load_folder + monkName + '_' + 'pca_original_dim'+str(R_est)+'.mat')\n",
    "pca_original_latent = np.copy(data['latents'])\n",
    "data=io.loadmat(load_folder + monkName + '_' + 'sca_original_dim'+str(R_est)+'.mat')\n",
    "sca_original_latent = np.copy(data['latents'])\n",
    "\n",
    "load_folder = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/'\n",
    "data = io.loadmat(load_folder+ monkName + '_proc_neural_data.mat')\n",
    "fit_data = np.copy(data['neuron_proc_activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveDir = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/subsamps/'\n",
    "figDir = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/subsamps/'\n",
    "T=data_downsamp.shape[2] \n",
    "trs=np.arange(0,8)\n",
    "t_idxs=[np.arange(T*tr,T*(tr+1)) for tr in trs]\n",
    "# define some useful time points\n",
    "tgt_idx=20\n",
    "move_idx=77\n",
    "ret_idx=200\n",
    "\n",
    "def subsamps(n_samps, n_nrns_arr):\n",
    "    dataL,numN = fit_data.shape #(2408, 124)\n",
    "    sca_latents = np.zeros((dataL,R_est,len(n_nrns_arr),n_samps))\n",
    "    pca_latents = np.zeros((dataL,R_est,len(n_nrns_arr),n_samps))\n",
    "    neuron_samps = []\n",
    "    sca_r = np.zeros((R_est,len(n_nrns_arr),n_samps))\n",
    "    pca_r = np.zeros((R_est,len(n_nrns_arr),n_samps))\n",
    "    neuron_index = []\n",
    "    k=0\n",
    "    for n_nrn in n_nrns_arr:\n",
    "        nrn_samps = np.zeros((dataL,n_nrn,n_samps))\n",
    "        nrn_index = np.zeros((n_nrn,n_samps))\n",
    "        for n in range(n_samps):\n",
    "            # draw 'numN' neurons with replacement\n",
    "            nIdx = np.random.choice(numN,n_nrn,replace=False)      \n",
    "            \n",
    "            #save sampled neuron indices\n",
    "            nrn_index[:,n] = nIdx\n",
    "            \n",
    "            #save sampled neuron pre-proceesed activity\n",
    "            X_samp = fit_data[:,nIdx]\n",
    "            nrn_samps[:,:,n] = X_samp\n",
    "            \n",
    "            # calculate our sample weights\n",
    "            sWeights = get_sample_weights(X_samp)\n",
    "\n",
    "            # run weighted pca\n",
    "            pca_uEst, pca_vEst = weighted_pca(X_samp[trainMask,:],R_est,sWeights[trainMask])\n",
    "\n",
    "            # pca latents\n",
    "            pca_lat = X_samp @ pca_uEst\n",
    "\n",
    "            #save pca rscore and latents\n",
    "            pca_r_list = np.zeros((R_est,1))\n",
    "            for i in range(R_est):\n",
    "                a = np.array([abs(pearsonr(pca_lat[:,i], pca_original_latent[:,j])[0]) for j in range(R_est)])\n",
    "                pca_r_list[i] = a.max()\n",
    "            pca_r[:,k,n] = pca_r_list.ravel()\n",
    "            pca_latents[:,:,k,n] = pca_lat\n",
    "            \n",
    "            # run sca\n",
    "            m, lt, y, lo = fit_ssa(X=X_samp[trainMask,:],R=R_est,sample_weight=sWeights[trainMask],orth = False)\n",
    "            #Get the low dimensional representation\n",
    "            sca_lat=X_samp@m.fc1.weight.detach().numpy().T+m.fc1.bias.detach().numpy()\n",
    "\n",
    "            #save sca rscore and latents\n",
    "            sca_r_list = np.zeros((R_est,1))\n",
    "            for i in range(R_est):\n",
    "                a = np.array([abs(pearsonr(sca_lat[:,i], sca_original_latent[:,j])[0]) for j in range(R_est)])\n",
    "                sca_r_list[i] = a.max()\n",
    "            sca_r[:,k,n] = sca_r_list.ravel()\n",
    "            sca_latents[:,:,k,n] = sca_lat\n",
    "            \n",
    "            if n < 1:\n",
    "                #save pca and sca latent plots for first sample\n",
    "                fig,ax=plt.subplots(R_est,1,figsize=(10,15))\n",
    "                for i in range(R_est):\n",
    "                    for j in range(len(trs)):\n",
    "\n",
    "                        ax[i].plot(pca_lat[:,i][t_idxs[j]] - np.mean(pca_lat[:,i]),linewidth=2.25,color=pca_cMap[j,:])\n",
    "\n",
    "                        ax[i].plot([tgt_idx,tgt_idx],[-1.7,1.7],'gray',linewidth=.5)\n",
    "                        ax[i].plot([move_idx,move_idx],[-2,2],'k',linewidth=.5)\n",
    "                        ax[i].plot([ret_idx,ret_idx],[-2,2],'k',linewidth=.5)\n",
    "\n",
    "                        ax[i].set_xlim([0,T+1])\n",
    "                        # ax[i].set_ylim([-2.5, 2.5])\n",
    "                        ax[i].plot([0,T],[0,0],'k--')\n",
    "                        if i<R_est-1:\n",
    "                            ax[i].set_xticks([])\n",
    "                        else:\n",
    "                            ax[i].set_xlabel('Time (10ms bins)')\n",
    "\n",
    "                        ax[i].set_yticks([])\n",
    "                        ax[i].set_ylabel('Dim. '+str(i+1))\n",
    "\n",
    "                    ax[0].set_title('Weighted PCA')\n",
    "                plt.savefig(figDir + monkName + '_pcaProj_ss' + str(n_nrn) + '.pdf',dpi = 'figure')\n",
    "                plt.close()\n",
    "                fig,ax=plt.subplots(R_est,1,figsize=(10,15))\n",
    "                for i in range(R_est):\n",
    "                    for j in range(len(trs)):\n",
    "\n",
    "                        ax[i].plot(sca_lat[:,i][t_idxs[j]] - np.mean(sca_lat[:,i]),linewidth=2.25,color=ssa_cMap[j,:])\n",
    "\n",
    "                        ax[i].plot([tgt_idx,tgt_idx],[-1.7,1.7],'gray',linewidth=.5)\n",
    "                        ax[i].plot([move_idx,move_idx],[-2,2],'k',linewidth=.5)\n",
    "                        ax[i].plot([ret_idx,ret_idx],[-2,2],'k',linewidth=.5)\n",
    "                        ax[i].plot([0,T],[0,0],'k--')\n",
    "\n",
    "                        ax[i].set_xlim([0,T+1])\n",
    "                        # ax[i].set_ylim([-2.5, 2.5])\n",
    "\n",
    "                        if i<R_est-1:\n",
    "                            ax[i].set_xticks([])\n",
    "                        else:\n",
    "                            ax[i].set_xlabel('Time (10ms bins)')\n",
    "\n",
    "                        ax[i].set_yticks([])\n",
    "                        ax[i].set_ylabel('Dim. '+str(i+1))\n",
    "\n",
    "                    ax[0].set_title('SCA Projections')\n",
    "                plt.savefig(figDir + monkName + '_scaProj_ss' + str(n_nrn) + '.pdf',dpi = 'figure')\n",
    "                plt.close()\n",
    "        k+=1\n",
    "    #save results \n",
    "    io.savemat(saveDir+ monkName + '_' + 'subsamps'+ '_dim' + str(R_est) + '.mat'\n",
    "           , {\"ss_sca_latents\": sca_latents, \"ss_pca_latents\": pca_latents\n",
    "           , \"ss_neuron_proc_activity\": neuron_samps, \"sca_absR\": sca_r, \"pca_absR\": pca_r\n",
    "           ,  \"ss_neuron_index\": neuron_index})\n",
    "    \n",
    "    return pca_r, sca_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nrns_arr = np.arange(40,101,20) #number of nrns, to draw the curve\n",
    "n_samps = 10 #per data point, how many draws\n",
    "pca_r, sca_r = subsamps(n_samps,n_nrns_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_est = 24\n",
    "n_samps = 10\n",
    "load_folder='/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/subsamps/'\n",
    "data=io.loadmat(load_folder + monkName + '_' + 'subsamps_dim'+str(R_est)+'.mat')\n",
    "pca_r = data['pca_absR']\n",
    "sca_r = data['sca_absR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = np.zeros((24, 1, 10))\n",
    "pca_r = np.concatenate((zeros, pca_r), axis=1)\n",
    "sca_r = np.concatenate((zeros, sca_r), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dist_samp_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dist_dim_mean = np.mean(pca_r,axis=0)\n",
    "sca_dist_dim_mean = np.mean(sca_r,axis=0)\n",
    "pca_dist_samp_mean = np.mean(pca_dist_dim_mean,axis=1)\n",
    "sca_dist_samp_mean = np.mean(sca_dist_dim_mean,axis=1)\n",
    "plt.plot(np.arange(40,101,20), pca_dist_samp_mean[1:],label='PCA',color='k',lw=2)\n",
    "plt.plot(np.arange(40,101,20), sca_dist_samp_mean[1:],label='SCA',color='purple',lw=2)\n",
    "plt.scatter(np.tile(n_nrns_arr,(n_samps,1)).T,pca_dist_dim_mean,color='k')\n",
    "plt.scatter(np.tile(n_nrns_arr,(n_samps,1)).T+2,sca_dist_dim_mean,color='purple')\n",
    "plt.legend()\n",
    "plt.ylabel('R')\n",
    "plt.xlabel('# of neurons')\n",
    "# plt.title('dim=8')\n",
    "plt.ylim([0.4,1.02])\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkName + '_subsamps_dim'+str(R_est)+'_r.pdf', dpi = 'figure')\n",
    "# sca_r = np.zeros((R_est,len(n_nrns_arr),n_samps))\n",
    "# plt.plot(pca_dist_mean[0],pca_dist_mean[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sca_latents = data[\"ss_sca_latents\"]\n",
    "pca_latents = data[\"ss_pca_latents\"]\n",
    "std_sca_latents = np.std(sca_latents,axis=0)\n",
    "std_pca_latents = np.std(pca_latents,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dist_dim_mean = np.sum(pca_r * std_pca_latents, axis=0) / np.sum(std_pca_latents, axis=0)\n",
    "sca_dist_dim_mean = np.sum(sca_r * std_sca_latents, axis=0) / np.sum(std_sca_latents, axis=0)\n",
    "pca_dist_samp_mean = np.mean(pca_dist_dim_mean,axis=1)\n",
    "sca_dist_samp_mean = np.mean(sca_dist_dim_mean,axis=1)\n",
    "plt.plot(n_nrns_arr, pca_dist_samp_mean,label='PCA',color='k',lw=2)\n",
    "plt.plot(n_nrns_arr, sca_dist_samp_mean,label='SCA',color='purple',lw=2)\n",
    "plt.scatter(np.tile(n_nrns_arr,(n_samps,1)).T,pca_dist_dim_mean,color='k')\n",
    "plt.scatter(np.tile(n_nrns_arr,(n_samps,1)).T+2,sca_dist_dim_mean,color='purple')\n",
    "plt.legend()\n",
    "plt.ylabel('Weighted R')\n",
    "plt.xlabel('# of neurons')\n",
    "plt.ylim([0.48,1.02])\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkName + '_subsamps_dim'+str(R_est)+'_weighted_r.pdf', dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_folder='/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/subsamps/'\n",
    "data=io.loadmat(load_folder + monkName + '_' + 'subsamps_dim8.mat')\n",
    "n_nrns_arr = np.arange(20,101,20)\n",
    "n_nrn_select = 20\n",
    "idx = np.argwhere(n_nrns_arr == n_nrn_select)[0,0]\n",
    "ssa_latent = data['ss_sca_latents'][:,:,idx,0]\n",
    "pca_latent = data['ss_pca_latents'][:,:,idx,0]\n",
    "pca_latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_folder='/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/original_fit/'\n",
    "data=io.loadmat(load_folder + monkName + '_' + 'pca_original_dim'+str(R_est)+'.mat')\n",
    "pca_latent = np.copy(data['latents'])\n",
    "data=io.loadmat(load_folder + monkName + '_' + 'sca_original_dim'+str(R_est)+'.mat')\n",
    "ssa_latent = np.copy(data['latents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate across-condition variance of each projection as a function of time\n",
    "R_est = 8\n",
    "# reshape both latents to be size T x C x K \n",
    "rs_sca_latent = np.reshape(ssa_latent,(-1,8,R_est),order = 'F')\n",
    "\n",
    "# calculate across condition variance\n",
    "sca_var = np.var(rs_sca_latent,axis = 1)\n",
    "\n",
    "# find peak occupancy of each dimension\n",
    "pkIdx = np.argmax(sca_var,axis = 0)\n",
    "\n",
    "# define plotting order\n",
    "sca_order = np.argsort(pkIdx)\n",
    "\n",
    "# resort ssa_latents by time of maximum occupancy\n",
    "rs_sca_latent = rs_sca_latent[:,:,sca_order]\n",
    "\n",
    "# do the same for the pca projections\n",
    "rs_pca_latent = np.reshape(pca_latent,(-1,8,R_est),order = 'F')\n",
    "\n",
    "pca_var = np.var(rs_pca_latent,axis = 1)\n",
    "pkIdx = np.argmax(pca_var,axis = 0)\n",
    "pca_order = np.argsort(pkIdx)\n",
    "rs_pca_latent = rs_pca_latent[:,:,pca_order]\n",
    "\n",
    "# define some useful time points\n",
    "tgt_idx=20\n",
    "move_idx=77\n",
    "ret_idx=200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# sca_cMap  = ['#5e0044', '#6f144e', '#812858', '#933c62', '#a5506d', '#b76477', '#c97881', '#db8c8c']\n",
    "# sca_cMap = ['#56143f','#69164a','#7d1e55','#902c60','#a43c6b','#b64f75','#c8637c','#db7986']\n",
    "# sca_cMap = ['#6c5f73','#76677b','#7e6e81','#877486','#8e7b8c','#968391','#9d8a95','#a4929b']\n",
    "pca_cMap = sns.cubehelix_palette(start = 0.1,rot = 0.6,dark = 0.15, light = 0.8,as_cmap = True,gamma = 0.7,hue = 0.3)\n",
    "pca_cMap = pca_cMap(colorIdx)\n",
    "pca_cMap = ['rgba({:.0f},{:.0f},{:.0f},{:.2f})'.format(r*255, g*255, b*255,a) for r, g, b, a in pca_cMap]\n",
    "\n",
    "sca_cMap = sns.cubehelix_palette(start = 0.1,rot = 0.6,dark = 0.15, light = 0.8,as_cmap = True,gamma = 1.1)\n",
    "sca_cMap = sca_cMap(colorIdx)\n",
    "sca_cMap = ['rgba({:.0f},{:.0f},{:.0f},{:.2f})'.format(r*255, g*255, b*255,a) for r, g, b, a in sca_cMap]\n",
    "\n",
    "# range for y axis\n",
    "yRange = [-0.8,0.8]\n",
    "\n",
    "fig = make_subplots(rows=R_est,cols = 1,shared_xaxes = True,vertical_spacing = 0)\n",
    "\n",
    "for ii in range(R_est):\n",
    "\n",
    "    for jj in range(numConds):\n",
    "        latTrace = go.Scatter(y = rs_sca_latent[:,jj,ii], line = go.scatter.Line(color = sca_cMap[jj],width = 0.8),showlegend = False)\n",
    "        fig.add_trace(latTrace,row = ii+1,col=1)\n",
    "        # if ii == (R_est-1):\n",
    "        #     fig.add_vline(x = tgt_idx,row = ii+1,col = 1, line_color = 'black')\n",
    "        #     fig.add_vline(x = move_idx,row = ii+1,col = 1, line_color = 'black')\n",
    "        #     fig.add_vline(x = ret_idx,row = ii+1,col = 1, line_color = 'black')\n",
    "\n",
    "            #\n",
    "    # add a vertical line for scale\n",
    "    scaleLine = go.Scatter(x = [0,0],y = [-0.2,0.2],showlegend = False,mode = 'lines',\n",
    "                            line = go.scatter.Line(color = 'black',width = 1.5))\n",
    "    fig.add_trace(scaleLine,row = ii+1,col = 1)\n",
    "\n",
    "\n",
    "fig.update_layout(height = 2000,width =600,title = 'SCA ' + monkName+' 20 nrns',title_font_color = 'black',\n",
    "                  paper_bgcolor = 'white',\n",
    "                  plot_bgcolor = 'white')\n",
    "fig.update_yaxes(showgrid = False,zeroline = False,visible = False,range = yRange)\n",
    "fig.update_xaxes(color = 'black',showgrid = False,zeroline = False,visible = False)\n",
    "# fig.update_xaxes(color = 'black',showgrid = False,zeroline = False,\n",
    "#                  ticks = 'outside',tickvals = [0,50],ticktext = ['0','500'],visible = True,row = R_est,col = 1)\n",
    "fig.update_xaxes(color = 'black',showgrid = False,zeroline = False,\n",
    "                 ticks = 'outside',tickvals = [20,50,77,200],ticktext = ['200','500','770','2000'],visible = True,row = R_est,col = 1)\n",
    "\n",
    "\n",
    "# save\n",
    "fig.write_image(figDir + monkName + 'SCA_20nrn.pdf')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# range for y axis\n",
    "yRange = [-0.8,0.8]\n",
    "\n",
    "fig = make_subplots(rows=R_est,cols = 1,shared_xaxes = True,vertical_spacing = 0)\n",
    "\n",
    "for ii in range(R_est):\n",
    "\n",
    "    for jj in range(numConds):\n",
    "        latTrace = go.Scatter(y = rs_pca_latent[:,jj,ii], line = go.scatter.Line(color = pca_cMap[jj],width = 0.8),showlegend = False)\n",
    "        fig.add_trace(latTrace,row = ii+1,col=1)\n",
    "        # if ii == (R_est-1):\n",
    "        #     fig.add_vline(x = tgt_idx,row = ii+1,col = 1, line_color = 'black')\n",
    "        #     fig.add_vline(x = move_idx,row = ii+1,col = 1, line_color = 'black')\n",
    "        #     fig.add_vline(x = ret_idx,row = ii+1,col = 1, line_color = 'black')\n",
    "\n",
    "            #\n",
    "    # add a vertical line for scale\n",
    "    scaleLine = go.Scatter(x = [0,0],y = [-0.2,0.2],showlegend = False,mode = 'lines',\n",
    "                            line = go.scatter.Line(color = 'black',width = 1.5))\n",
    "    fig.add_trace(scaleLine,row = ii+1,col = 1)\n",
    "\n",
    "\n",
    "fig.update_layout(height = 2000,width =600,title = 'PCA ' + monkName+' 20 nrns',title_font_color = 'black',\n",
    "                  paper_bgcolor = 'white',\n",
    "                  plot_bgcolor = 'white')\n",
    "fig.update_yaxes(showgrid = False,zeroline = False,visible = False,range = yRange)\n",
    "fig.update_xaxes(color = 'black',showgrid = False,zeroline = False,visible = False)\n",
    "# fig.update_xaxes(color = 'black',showgrid = False,zeroline = False,\n",
    "#                  ticks = 'outside',tickvals = [0,50],ticktext = ['0','500'],visible = True,row = R_est,col = 1)\n",
    "fig.update_xaxes(color = 'black',showgrid = False,zeroline = False,\n",
    "                 ticks = 'outside',tickvals = [20,50,77,200],ticktext = ['200','500','770','2000'],visible = True,row = R_est,col = 1)\n",
    "\n",
    "\n",
    "# save\n",
    "fig.write_image(figDir + monkName + 'PCA_20nrn.pdf')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA/SCA dimension consistency in bootstrapping neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figDir = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/bootstraps/'\n",
    "saveDir = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/bootstraps/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_original_latent = np.copy(pca_latent)\n",
    "print(pca_original_latent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sca_original_latent = np.copy(ssa_latent)\n",
    "print(sca_original_latent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Color theme: red\n",
    "colorIdx = np.arange(0.55,1,0.4/8)\n",
    "\n",
    "# define ssa colors\n",
    "ssa_cMap = sns.cubehelix_palette(start = 0.1,rot = 0.6,dark = 0.15, light = 0.8,as_cmap = True,gamma = 1.1)\n",
    "ssa_cMap = ssa_cMap(colorIdx)\n",
    "\n",
    "# define pca colors\n",
    "pca_cMap = sns.cubehelix_palette(start = 0.1,rot = 0.6,dark = 0.15, light = 0.8,as_cmap = True,gamma = 0.7,hue = 0.3)\n",
    "pca_cMap = pca_cMap(colorIdx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array_copy = np.copy(data_array)\n",
    "def bootstraps(n_boots):\n",
    "    dataL,numN = fit_data.shape\n",
    "    sca_latents = np.zeros((dataL,R_est,n_boots))\n",
    "    pca_latents = np.zeros((dataL,R_est,n_boots))\n",
    "    neuron_samps = np.zeros((dataL,numN,n_boots))\n",
    "    sca_r = np.zeros((R_est,n_boots))\n",
    "    pca_r = np.zeros((R_est,n_boots))\n",
    "    neuron_index = np.zeros((numN,n_boots))\n",
    "\n",
    "    for n in range(n_boots):\n",
    "        # draw 'numN' neurons with replacement\n",
    "        nIdx = np.random.choice(numN,numN)      \n",
    "        \n",
    "        #save sampled neuron indices\n",
    "        neuron_index[:,n] = nIdx\n",
    "        \n",
    "        #save sampled neuron pre-proceesed activity\n",
    "        X_samp = fit_data[:,nIdx]\n",
    "        neuron_samps[:,:,n] = X_samp\n",
    "        \n",
    "        # calculate our sample weights\n",
    "        sWeights = get_sample_weights(X_samp)\n",
    "\n",
    "        # run weighted pca\n",
    "        pca_uEst, pca_vEst = weighted_pca(X_samp[trainMask,:],R_est,sWeights[trainMask])\n",
    "\n",
    "        # pca latents\n",
    "        pca_lat = X_samp @ pca_uEst\n",
    "\n",
    "        #save pca rscore and latents\n",
    "        pca_r_list = np.zeros((R_est,1))\n",
    "        for i in range(R_est):\n",
    "            a = np.array([abs(pearsonr(pca_lat[:,i], pca_original_latent[:,j])[0]) for j in range(R_est)])\n",
    "            pca_r_list[i] = a.max()\n",
    "        pca_r[:,n] = pca_r_list.ravel()\n",
    "        pca_latents[:,:,n] = pca_lat\n",
    "        \n",
    "        # run sca\n",
    "        m, lt, y, lo = fit_ssa(X=X_samp[trainMask,:],R=R_est,sample_weight=sWeights[trainMask],orth = False)\n",
    "        #Get the low dimensional representation\n",
    "        sca_lat=X_samp@m.fc1.weight.detach().numpy().T+m.fc1.bias.detach().numpy()\n",
    "\n",
    "        #save sca rscore and latents\n",
    "        sca_r_list = np.zeros((R_est,1))\n",
    "        for i in range(R_est):\n",
    "            a = np.array([abs(pearsonr(sca_lat[:,i], sca_original_latent[:,j])[0]) for j in range(R_est)])\n",
    "            sca_r_list[i] = a.max()\n",
    "        sca_r[:,n] = sca_r_list.ravel()\n",
    "        sca_latents[:,:,n] = sca_lat\n",
    "        \n",
    "        if n < 5:\n",
    "            #save pca and sca latent plots for first 5 bootstraps\n",
    "            fig,ax=plt.subplots(R_est,1,figsize=(10,15))\n",
    "            for i in range(R_est):\n",
    "                for j in range(len(trs)):\n",
    "\n",
    "                    ax[i].plot(pca_lat[:,i][t_idxs[j]] - np.mean(pca_lat[:,i]),linewidth=2.25,color=pca_cMap[j,:])\n",
    "\n",
    "                    ax[i].plot([tgt_idx,tgt_idx],[-1.7,1.7],'gray',linewidth=.5)\n",
    "                    ax[i].plot([move_idx,move_idx],[-2,2],'k',linewidth=.5)\n",
    "                    ax[i].plot([ret_idx,ret_idx],[-2,2],'k',linewidth=.5)\n",
    "\n",
    "                    ax[i].set_xlim([0,T+1])\n",
    "                    ax[i].set_ylim([-2.5, 2.5])\n",
    "                    ax[i].plot([0,T],[0,0],'k--')\n",
    "                    if i<R_est-1:\n",
    "                        ax[i].set_xticks([])\n",
    "                    else:\n",
    "                        ax[i].set_xlabel('Time (10ms bins)')\n",
    "\n",
    "                    ax[i].set_yticks([])\n",
    "                    ax[i].set_ylabel('Dim. '+str(i+1))\n",
    "\n",
    "                ax[0].set_title('Weighted PCA')\n",
    "            plt.savefig(figDir + monkName + '_pcaProj_bs' + str(n) + '.pdf',dpi = 'figure')\n",
    "            plt.close()\n",
    "            fig,ax=plt.subplots(R_est,1,figsize=(10,15))\n",
    "            for i in range(R_est):\n",
    "                for j in range(len(trs)):\n",
    "\n",
    "                    ax[i].plot(sca_lat[:,i][t_idxs[j]] - np.mean(sca_lat[:,i]),linewidth=2.25,color=ssa_cMap[j,:])\n",
    "\n",
    "                    ax[i].plot([tgt_idx,tgt_idx],[-1.7,1.7],'gray',linewidth=.5)\n",
    "                    ax[i].plot([move_idx,move_idx],[-2,2],'k',linewidth=.5)\n",
    "                    ax[i].plot([ret_idx,ret_idx],[-2,2],'k',linewidth=.5)\n",
    "                    ax[i].plot([0,T],[0,0],'k--')\n",
    "\n",
    "                    ax[i].set_xlim([0,T+1])\n",
    "                    ax[i].set_ylim([-2.5, 2.5])\n",
    "\n",
    "                    if i<R_est-1:\n",
    "                        ax[i].set_xticks([])\n",
    "                    else:\n",
    "                        ax[i].set_xlabel('Time (10ms bins)')\n",
    "\n",
    "                    ax[i].set_yticks([])\n",
    "                    ax[i].set_ylabel('Dim. '+str(i+1))\n",
    "\n",
    "                ax[0].set_title('SCA Projections')\n",
    "            plt.savefig(figDir + monkName + '_scaProj_bs' + str(n) + '.png',dpi = 'figure')\n",
    "            plt.close()\n",
    "    #save bootstraping results for Gamal    \n",
    "    io.savemat(saveDir+ monkName + '_' + 'bootstraps'+ '_' + str(n+1) + '_dim' + str(R_est) + '.mat'\n",
    "           , {\"bs_sca_latents\": sca_latents, \"bs_pca_latents\": pca_latents\n",
    "           , \"bs_neuron_proc_activity\": neuron_samps, \"sca_absR\": sca_r, \"pca_absR\": pca_r,\n",
    "             \"original_data\": data_array_copy, \"bs_neuron_index\": neuron_index})\n",
    "    \n",
    "    return pca_r, sca_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run bootstraps, get arrays of absolute Pearson's R's\n",
    "numBoots = 100\n",
    "pca_r, sca_r = bootstraps(numBoots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_folder='/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/bootstraps/'\n",
    "data=io.loadmat(load_folder + monkName + '_' + 'bootstraps_100_dim24.mat')\n",
    "pca_r = data['pca_absR']\n",
    "sca_r = data['sca_absR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Color theme: blue\n",
    "# define ssa colors\n",
    "ssa_cMap = sns.cubehelix_palette(start = 2,rot = 0.6,dark = 0.15, light = 0.8,as_cmap = True,gamma = 1.1)\n",
    "ssa_cMap = ssa_cMap(colorIdx)\n",
    "\n",
    "# define pca colors\n",
    "pca_cMap = sns.cubehelix_palette(start = 2,rot = 0.6,dark = 0.15, light = 0.8,as_cmap = True,gamma = 0.7,hue = 0.3)\n",
    "pca_cMap = pca_cMap(colorIdx)# fraction of colormap to use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dist_mean = [np.mean(pca_r[:,i]) for i in range(pca_r.shape[1])]\n",
    "sca_dist_mean = [np.mean(sca_r[:,i]) for i in range(sca_r.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot bootstraping distribution of MEAN absolute Pearson's R for PCA and SCA\n",
    "# plt.title(\"SCA/PCA mean abs(R), boots n=\" + str(pca_r.shape[1]))\n",
    "plt.hist(pca_dist_mean, bins=np.arange(.3, 1.05, 0.05),color=pca_cMap[0,:],alpha = .7, label = 'PCA') \n",
    "plt.hist(sca_dist_mean, bins=np.arange(.3, 1.05, 0.05),color=ssa_cMap[0,:],alpha = .7,label = 'SCA') \n",
    "legend = plt.legend();\n",
    "figDir = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/bootstraps/'\n",
    "plt.xlabel('absolute Pearson R');\n",
    "plt.ylabel('Frequency');\n",
    "plt.tight_layout()\n",
    "# save\n",
    "plt.savefig(figDir + monkName + '_meanabs.pdf', dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dist_median = [np.median(pca_r[:,i]) for i in range(pca_r.shape[1])]\n",
    "sca_dist_median = [np.median(sca_r[:,i]) for i in range(sca_r.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot bootstraping distribution of MEDIAN absolute Pearson's R for PCA and SCA\n",
    "# plt.title(\"SCA/PCA median abs(R), boots n=\" + str(pca_r.shape[1]))\n",
    "plt.hist(pca_dist_median, bins=np.arange(.3, 1.05, 0.05),color=pca_cMap[0,:],alpha = .7, label = 'PCA') \n",
    "plt.hist(sca_dist_median, bins=np.arange(.3, 1.05, 0.05),color=ssa_cMap[0,:],alpha = .7,label = 'SCA') \n",
    "legend = plt.legend();\n",
    "plt.xlabel('absolute Pearson R');\n",
    "plt.ylabel('Frequency');\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkName + '_medianabs.pdf', dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot pairwise difference in MEAN absolute Pearson's R \n",
    "r2meanDiff_dist = [np.mean(sca_r[:,i])-np.mean(pca_r[:,i]) for i in range(pca_r.shape[1])]\n",
    "# plt.title(\"SCA minus PCA mean abs(R), boots n=\" + str(pca_r.shape[1]))\n",
    "plt.hist(r2meanDiff_dist, bins=np.arange(-0.5, 0.55, 0.05),color=pca_cMap[0,:],alpha = .7)\n",
    "plt.axvline(x = 0, linestyle =\"--\",color='k')\n",
    "prop = sum(1 for i in r2meanDiff_dist if i > 0)/len(r2meanDiff_dist)\n",
    "plt.text(.3, 15, str(prop*100) +'%', style='italic')\n",
    "plt.xlabel('absolute Pearson R difference');\n",
    "plt.ylabel('Frequency');\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkName + '_meanabsdiff.pdf', dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot pairwise difference in MEDIAN absolute Pearson's R \n",
    "r2medianDiff_dist = [np.median(sca_r[:,i])-np.median(pca_r[:,i]) for i in range(pca_r.shape[1])]\n",
    "# plt.title(\"SCA minus PCA median abs(R), boots n=\" + str(pca_r.shape[1]))\n",
    "plt.hist(r2medianDiff_dist, bins=np.arange(-0.5, 0.55, 0.05),color=pca_cMap[0,:],alpha = .7)\n",
    "plt.axvline(x = 0, linestyle =\"--\",color='k')\n",
    "prop = sum(1 for i in r2medianDiff_dist if i > 0)/len(r2medianDiff_dist)\n",
    "plt.text(.3, 15, str(prop*100) +'%', style='italic')\n",
    "plt.xlabel('absolute Pearson R difference');\n",
    "plt.ylabel('Frequency');\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkName + '_medianabsdiff.pdf', dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Color theme: pink\n",
    "colorIdx = np.arange(0.55,1,0.4/8)\n",
    "\n",
    "# define ssa colors\n",
    "ssa_cMap = sns.cubehelix_palette(start = 0.1,rot = 0.6,dark = 0.15, light = 0.8,as_cmap = True,gamma = 1.1)\n",
    "ssa_cMap = ssa_cMap(colorIdx)\n",
    "\n",
    "# define pca colors\n",
    "pca_cMap = sns.cubehelix_palette(start = 0.1,rot = 0.6,dark = 0.15, light = 0.8,as_cmap = True,gamma = 0.7,hue = 0.3)\n",
    "pca_cMap = pca_cMap(colorIdx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate R^2\n",
    "pca_r2 = np.square(pca_r)\n",
    "sca_r2 = np.square(sca_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_pca_dist_mean = [np.mean(pca_r2[:,i]) for i in range(pca_r.shape[1])]\n",
    "s_sca_dist_mean = [np.mean(sca_r2[:,i]) for i in range(sca_r.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot bootstraping distribution of MEAN R^2 for PCA and SCA\n",
    "# plt.title(\"SCA/PCA mean R^2, boots n=\" + str(pca_r.shape[1]))\n",
    "plt.hist(s_pca_dist_mean, bins=np.arange(0.1, 1.05, 0.05),color=pca_cMap[0,:],alpha = .7, label = 'PCA') \n",
    "plt.hist(s_sca_dist_mean, bins=np.arange(0.1, 1.05, 0.05),color=ssa_cMap[0,:],alpha = .7,label = 'SCA') \n",
    "legend = plt.legend();\n",
    "plt.xlabel('R^2');\n",
    "plt.ylabel('Frequency');\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkName + '_meanr2.pdf', dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_pca_dist_median = [np.median(pca_r2[:,i]) for i in range(pca_r.shape[1])]\n",
    "s_sca_dist_median = [np.median(sca_r2[:,i]) for i in range(sca_r.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot bootstraping distribution of MEDIAN R^2 for PCA and SCA\n",
    "# plt.title(\"SCA/PCA median R^2, boots n=\" + str(pca_r.shape[1]))\n",
    "plt.hist(s_pca_dist_median, bins=np.arange(0.1, 1.05, 0.05),color=pca_cMap[0,:],alpha = .7, label = 'PCA') \n",
    "plt.hist(s_sca_dist_median, bins=np.arange(0.1, 1.05, 0.05),color=ssa_cMap[0,:],alpha = .7,label = 'SCA') \n",
    "legend = plt.legend();\n",
    "plt.xlabel('R^2');\n",
    "plt.ylabel('Frequency');\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkName + '_medianr2.pdf', dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot pairwise difference in MEAN R^2\n",
    "s_r2meanDiff_dist = [np.mean(sca_r2[:,i])-np.mean(pca_r2[:,i]) for i in range(pca_r.shape[1])]\n",
    "# plt.title(\"SCA minus PCA mean R^2, boots n=\" + str(pca_r.shape[1]))\n",
    "plt.hist(s_r2meanDiff_dist, bins=np.arange(-0.5, 0.55, 0.05),color=pca_cMap[0,:],alpha = .7)\n",
    "plt.axvline(x = 0, linestyle =\"--\",color='k')\n",
    "prop = sum(1 for i in s_r2meanDiff_dist if i > 0)/len(s_r2meanDiff_dist)\n",
    "plt.text(.3, 13, str(prop*100) +'%', style='italic')\n",
    "plt.xlabel('R^2 difference');\n",
    "plt.ylabel('Frequency');\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkName + '_meanr2diff.pdf', dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot pairwise difference in MEDIAN R^2\n",
    "s_r2medianDiff_dist = [np.median(sca_r2[:,i])-np.median(pca_r2[:,i]) for i in range(pca_r.shape[1])]\n",
    "# plt.title(\"SCA minus PCA median R^2, boots n=\" + str(pca_r.shape[1]))\n",
    "plt.hist(s_r2medianDiff_dist, bins=np.arange(-0.5, 0.55, 0.05),color=pca_cMap[0,:],alpha = .7)\n",
    "plt.axvline(x = 0, linestyle =\"--\",color='k')\n",
    "prop = sum(1 for i in s_r2medianDiff_dist if i > 0)/len(s_r2medianDiff_dist)\n",
    "plt.text(.3, 13, str(prop*100) +'%', style='italic')\n",
    "plt.xlabel('R^2 difference')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkName + '_medianr2diff.pdf', dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape pca reconstructions\n",
    "pcaR = np.reshape(pca_r2,[-1,1],order = 'F')\n",
    "\n",
    "# plot pca results with a small amount of jitter around 1\n",
    "pcaLoc = np.random.normal(loc = 1,scale = 0.03,size = (numBoots*R_est,1))\n",
    "\n",
    "# plot pca reconstractions across neurons and across bootstraps\n",
    "plt.plot(pcaLoc,pcaR,'o',color = (0.4,0.4,0.4),ms = 4,alpha = 0.02);\n",
    "\n",
    "# plot the mean and std of pca performance\n",
    "plt.errorbar(1,np.mean(pcaR),np.std(pcaR),color = 'k',lw = 3,zorder = 3,label = 'PCA')\n",
    "plt.plot(1,np.mean(pcaR),'o',color = 'k',ms = 8,zorder = 3);\n",
    "\n",
    "# now SCA\n",
    "scaR = np.reshape(sca_r2,[-1,1],order = 'F')\n",
    "\n",
    "# get jittered position for ssa reconstructions\n",
    "scaLoc = np.random.normal(loc = 2,scale = 0.03,size = (numBoots*R_est,1))\n",
    "plt.plot(scaLoc,scaR,'o',color = 'darkblue',ms = 4, alpha = 0.02);\n",
    "\n",
    "# plot the mean and std of ssa performance\n",
    "plt.errorbar(2,np.mean(scaR),np.std(scaR) ,color = 'darkblue',lw = 3, zorder =3,label = 'SCA')\n",
    "plt.plot(2,np.mean(scaR),'o',color = 'darkblue',ms = 8,zorder=3);\n",
    "\n",
    "# clean up\n",
    "plt.xlim((0.5, 2.5));plt.ylim((0,1));\n",
    "plt.xticks(np.array([1,2]),('PCA','SSA'));\n",
    "plt.yticks(np.array([0,0.5, 1]));\n",
    "plt.ylabel('R^2');\n",
    "# plt.title(\"\")\n",
    "legend = plt.legend(loc = 'lower right');\n",
    "plt.tight_layout()\n",
    "# # # save directory\n",
    "figDir = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/bootstraps/'\n",
    "\n",
    "# # save\n",
    "plt.savefig(figDir + monkName + '_Orig_r2_dist.pdf', dpi = 'figure')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test SCA explanatory power with Gamal projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Gamal results in bootstraps\n",
    "monkName = 'Alex'\n",
    "load_folder='/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/bootstraps/'\n",
    "gamal_data=io.loadmat(load_folder + monkName + '_bs_100_gamalLoadings.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defind prep, move, and post projections\n",
    "gamal_PrepProj = gamal_data['prepProj_list'][:,:,:,None]\n",
    "gamal_MoveProj = gamal_data['moveProj_list'][:,:,:,None]\n",
    "gamal_PostProj = gamal_data['postProj_list'][:,:,:,None]\n",
    "print(gamal_PrepProj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load PCA and SCA bootstrapping results\n",
    "load_folder='/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/bootstraps/'\n",
    "boot_data=io.loadmat(load_folder + monkName + '_bootstraps_100_dim8.mat')\n",
    "print(boot_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sca_latents = boot_data['bs_sca_latents']\n",
    "pca_latents = boot_data['bs_pca_latents']\n",
    "print(pca_latents.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_folder='/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/bootstraps/'\n",
    "boot_data=io.loadmat(load_folder + monkName + '_bs_100_MIX_gamalLoadings.mat')\n",
    "print(boot_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_gamal_latents = np.concatenate([boot_data['mixProj_list'][:,:4,:],boot_data['prepProj_list'][:,:4,:]],axis=1)\n",
    "print(mix_gamal_latents.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_est = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define some new colormaps\n",
    "# fraction of colormap to use\n",
    "colorIdx = np.arange(0.55,1,0.4/8)\n",
    "\n",
    "# define prep colors\n",
    "prep_cMap = sns.cubehelix_palette(start = 2,rot = 0,dark = 0.15, light = 0.8,as_cmap = True,gamma = 1.1)\n",
    "prep_cMap = prep_cMap(colorIdx)\n",
    "\n",
    "# move colors\n",
    "move_cMap = sns.cubehelix_palette(start = 2.35,rot = 0,dark = 0.15, light = 0.8,as_cmap = True,gamma = 0.7)\n",
    "move_cMap = move_cMap(colorIdx)\n",
    "\n",
    "# posture colors\n",
    "post_cMap = sns.cubehelix_palette(start = 2.8,rot = 0,dark = 0.15, light = 0.8,as_cmap = True,gamma = 0.7)\n",
    "post_cMap = post_cMap(colorIdx)\n",
    "\n",
    "# plot colors\n",
    "plt.figure(figsize = (5,5));\n",
    "plt.subplot(311);\n",
    "for i in np.arange(8):\n",
    "    plt.plot(np.arange(0,10)*i,color = prep_cMap[i,:],linewidth = 8);\n",
    "\n",
    "plt.subplot(312);\n",
    "for i in np.arange(8):\n",
    "    plt.plot(np.arange(0,10)*i,color = move_cMap[i,:],linewidth = 8);\n",
    "\n",
    "plt.subplot(313);\n",
    "for i in np.arange(8):\n",
    "    plt.plot(np.arange(0,10)*i,color = post_cMap[i,:],linewidth = 8);\n",
    "\n",
    "# concatenate colormaps\n",
    "prep_cMap = prep_cMap[:,:,None]\n",
    "move_cMap = move_cMap[:,:,None]\n",
    "post_cMap = post_cMap[:,:,None]\n",
    "\n",
    "g_cMap = np.concatenate((prep_cMap, move_cMap, post_cMap),axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot Gamal projections for first 5 bootstraps\n",
    "for n in range(5):\n",
    "    gProj = np.concatenate((gamal_PrepProj[:,:,n],gamal_MoveProj[:,:,n],gamal_PostProj[:,:,n]),axis = -1)\n",
    "\n",
    "    #Get indices of each trial\n",
    "    T=data_downsamp.shape[2] #Length of time per condition\n",
    "    trs=np.arange(0,8)\n",
    "    t_idxs=[np.arange(T*tr,T*(tr+1)) for tr in trs]\n",
    "\n",
    "    # define some useful time points\n",
    "    tgt_idx=20\n",
    "    move_idx=77\n",
    "    ret_idx=200\n",
    "\n",
    "    # change color of axis labels so we can see them in the pdf\n",
    "    plt.rcParams['text.color'] = 'k'\n",
    "    plt.rcParams['xtick.color'] = 'k'\n",
    "    plt.rcParams['ytick.color'] = 'k'\n",
    "    plt.rcParams['axes.labelcolor'] = 'k'\n",
    "\n",
    "    fig,ax=plt.subplots(12,3,figsize=(15,20))\n",
    "    for E in range(3):\n",
    "\n",
    "        for i in range(12):\n",
    "            for j in range(len(trs)):\n",
    "\n",
    "                ax[i,E].plot(gProj[:,i,E][t_idxs[j]],linewidth=2.25,color=g_cMap[j,:,E])\n",
    "\n",
    "                ax[i,E].plot([tgt_idx,tgt_idx],[-100,100],'gray',linewidth=.5)\n",
    "                ax[i,E].plot([move_idx,move_idx],[-100,100],'k',linewidth=.5)\n",
    "                ax[i,E].plot([ret_idx,ret_idx],[-100,100],'k',linewidth=.5)\n",
    "\n",
    "                ax[i,E].set_xlim([0,T+1])\n",
    "                ax[i,E].set_ylim([-2, 2])\n",
    "\n",
    "                if i<12-1:\n",
    "                    ax[i,E].set_xticks([])\n",
    "                else:\n",
    "                    ax[i,E].set_xlabel('Time (10ms bins)')\n",
    "\n",
    "                ax[i,E].set_yticks([])\n",
    "                ax[i,E].set_ylabel('Dim. '+str(i+1))\n",
    "\n",
    "    ax[0,0].set_title('Preparation Projections')\n",
    "    ax[0,1].set_title('Move Projections')\n",
    "    ax[0,2].set_title('Posture Projections')\n",
    "    # save figure\n",
    "\n",
    "    # save directory\n",
    "    figDir = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/bootstraps/'\n",
    "\n",
    "    # save\n",
    "    plt.savefig(figDir + monkName + '_bs' +  str(n) + '_gamalProj.pdf',dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IND BEHAV\n",
    "\n",
    "# number of bootstraps\n",
    "numBoots = gamal_PrepProj.shape[2]\n",
    "\n",
    "# initialize vector to hold R2\n",
    "# each -1 dimenision corresponds to the reconstruction R2 from the prep, move, or posture projections\n",
    "# allR2_pca = np.zeros((numBoots,R_est,3))\n",
    "allR2_mgamal = np.zeros((numBoots,R_est,3))\n",
    "allR2_sca = np.zeros((numBoots,R_est,3))\n",
    "\n",
    "# cycle through bootstrap repetitions\n",
    "for n in range(numBoots):\n",
    "    gProj = np.concatenate((gamal_PrepProj[:,:,n],gamal_MoveProj[:,:,n],gamal_PostProj[:,:,n]),axis = -1)\n",
    "\n",
    "    # # pull out PCA bootstrap latents\n",
    "    # Y = pca_latents[:,:,n]\n",
    "\n",
    "    # # get B (regression weights) from prep, move, and posture projections\n",
    "    # for e in np.arange(3):\n",
    "\n",
    "    #     # make life a bit easier and just pull out the gamal projections we want\n",
    "    #     X = gProj[:,:,e]\n",
    "\n",
    "    #     # regress\n",
    "    #     B = np.linalg.inv(X.T@X) @ X.T @ Y\n",
    "\n",
    "    #     # reconstruct Y \n",
    "    #     Y_hat = X @ B\n",
    "    \n",
    "    #     # calculate R2\n",
    "    #     ss_tot = np.sum((Y - np.mean(Y,axis = 0))**2, axis = 0)\n",
    "    #     ss_res = np.sum((Y - Y_hat)**2,axis = 0)\n",
    "    #     allR2_pca[n,:,e] = 1 - (ss_res/ss_tot)\n",
    "\n",
    "    # pull out Mixed Gamal bootstrap latents\n",
    "    Y = mix_gamal_latents[:,:,n]\n",
    "\n",
    "    # get B (regression weights) from prep, move, and posture projections\n",
    "    for e in np.arange(3):\n",
    "\n",
    "        # make life a bit easier and just pull out the gamal projections we want\n",
    "        X = gProj[:,:,e]\n",
    "\n",
    "        # regress\n",
    "        B = np.linalg.inv(X.T@X) @ X.T @ Y\n",
    "\n",
    "        # reconstruct Y \n",
    "        Y_hat = X @ B\n",
    "    \n",
    "        # calculate R2\n",
    "        ss_tot = np.sum((Y - np.mean(Y,axis = 0))**2, axis = 0)\n",
    "        ss_res = np.sum((Y - Y_hat)**2,axis = 0)\n",
    "        allR2_mgamal[n,:,e] = 1 - (ss_res/ss_tot)        \n",
    "\n",
    "    # pull out SCA bootstrap latents\n",
    "    Y = sca_latents[:,:,n]\n",
    "\n",
    "    # get B (regression weights) from prep, move, and posture projections\n",
    "    for e in np.arange(3):\n",
    "\n",
    "        # make life a bit easier and just pull out the gamal projections we want\n",
    "        X = gProj[:,:,e]\n",
    "\n",
    "        # regress\n",
    "        B = np.linalg.inv(X.T@X) @ X.T @ Y\n",
    "\n",
    "        # reconstruct Y \n",
    "        Y_hat = X @ B\n",
    " \n",
    "        # calculate R2\n",
    "        ss_tot = np.sum((Y - np.mean(Y,axis = 0))**2, axis = 0)\n",
    "        ss_res = np.sum((Y - Y_hat)**2,axis = 0)\n",
    "        allR2_sca[n,:,e] = 1 - (ss_res/ss_tot)\n",
    "\n",
    "# take max R2 for each dimension \n",
    "maxR2_mgamal = np.max(allR2_mgamal,axis = 2)\n",
    "maxR2_sca = np.max(allR2_sca,axis = 2)\n",
    "\n",
    "#print first bootstrap's max R2's\n",
    "print(maxR2_mgamal[0])\n",
    "print(maxR2_sca[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL BEHAV\n",
    "\n",
    "# number of bootstraps\n",
    "numBoots = gamal_PrepProj.shape[2]\n",
    "\n",
    "# initialize vector to hold R2\n",
    "# allR2_pca = np.zeros((numBoots,R_est))\n",
    "allR2_mgamal = np.zeros((numBoots,R_est))\n",
    "allR2_sca = np.zeros((numBoots,R_est))\n",
    "\n",
    "# cycle through bootstrap repetitions\n",
    "for n in range(numBoots):\n",
    "    gProj = np.concatenate((gamal_PrepProj[:,:,n],gamal_MoveProj[:,:,n],gamal_PostProj[:,:,n]),axis = -1)\n",
    "    gProj = gProj.reshape(gProj.shape[0],-1)\n",
    "    # # pull out PCA bootstrap latents\n",
    "    # Y = pca_latents[:,:,n]\n",
    "\n",
    "    # # pull out all gamal projections\n",
    "    # X = gProj\n",
    "\n",
    "    # # regress\n",
    "    # B = np.linalg.inv(X.T@X) @ X.T @ Y\n",
    "\n",
    "    # # reconstruct Y \n",
    "    # Y_hat = X @ B\n",
    "\n",
    "    # # calculate R2\n",
    "    # ss_tot = np.sum((Y - np.mean(Y,axis = 0))**2, axis = 0)\n",
    "    # ss_res = np.sum((Y - Y_hat)**2,axis = 0)\n",
    "    # allR2_pca[n,:] = 1 - (ss_res/ss_tot)\n",
    "\n",
    "    # pull out mixed gamal bootstrap latents\n",
    "    Y = mix_gamal_latents[:,:,n]\n",
    "\n",
    "    # pull out all gamal projections\n",
    "    X = gProj\n",
    "\n",
    "    # regress\n",
    "    B = np.linalg.inv(X.T@X) @ X.T @ Y\n",
    "\n",
    "    # reconstruct Y \n",
    "    Y_hat = X @ B\n",
    "\n",
    "    # calculate R2\n",
    "    ss_tot = np.sum((Y - np.mean(Y,axis = 0))**2, axis = 0)\n",
    "    ss_res = np.sum((Y - Y_hat)**2,axis = 0)\n",
    "    allR2_mgamal[n,:] = 1 - (ss_res/ss_tot)\n",
    "\n",
    "    # pull out SCA bootstrap latents\n",
    "    Y = sca_latents[:,:,n]\n",
    "\n",
    "    # pull out all gamal projections\n",
    "    X = gProj\n",
    "\n",
    "    # regress\n",
    "    B = np.linalg.inv(X.T@X) @ X.T @ Y\n",
    "\n",
    "    # reconstruct Y \n",
    "    Y_hat = X @ B\n",
    "\n",
    "    # calculate R2\n",
    "    ss_tot = np.sum((Y - np.mean(Y,axis = 0))**2, axis = 0)\n",
    "    ss_res = np.sum((Y - Y_hat)**2,axis = 0)\n",
    "    allR2_sca[n,:] = 1 - (ss_res/ss_tot)\n",
    "\n",
    "#print first bootstrap's max R2's\n",
    "print(allR2_mgamal[0])\n",
    "print(allR2_sca[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change color of axis labels so we can see them in the pdf\n",
    "plt.rcParams['text.color'] = 'k'\n",
    "plt.rcParams['xtick.color'] = 'k'\n",
    "plt.rcParams['ytick.color'] = 'k'\n",
    "plt.rcParams['axes.labelcolor'] = 'k'\n",
    "\n",
    "# reshape pca reconstructions\n",
    "pcaR2_recon = np.reshape(maxR2_mgamal,[-1,1],order = 'F')\n",
    "\n",
    "# plot pca results with a small amount of jitter around 1\n",
    "pcaLoc = np.random.normal(loc = 1,scale = 0.03,size = (numBoots*R_est,1))\n",
    "\n",
    "# plot pca reconstractions across neurons and across bootstraps\n",
    "plt.plot(pcaLoc,pcaR2_recon,'o',color = (0.4,0.4,0.4),ms = 4,alpha = 0.02);\n",
    "\n",
    "# plot the mean and std of pca performance\n",
    "plt.errorbar(1,np.mean(pcaR2_recon),np.std(pcaR2_recon),color = 'k',lw = 3,zorder = 3,label = 'PCA')\n",
    "plt.plot(1,np.mean(pcaR2_recon),'o',color = 'k',ms = 8,zorder = 3);\n",
    "\n",
    "# now SCA\n",
    "scaR2_recon = np.reshape(maxR2_sca,[-1,1],order = 'F')\n",
    "\n",
    "# get jittered position for ssa reconstructions\n",
    "scaLoc = np.random.normal(loc = 2,scale = 0.03,size = (numBoots*R_est,1))\n",
    "plt.plot(scaLoc,scaR2_recon,'o',color = 'purple',ms = 4, alpha = 0.02);\n",
    "\n",
    "# plot the mean and std of ssa performance\n",
    "plt.errorbar(2,np.mean(scaR2_recon),np.std(scaR2_recon) ,color = 'purple',lw = 3, zorder =3,label = 'SCA')\n",
    "plt.plot(2,np.mean(scaR2_recon),'o',color = 'purple',ms = 8,zorder=3);\n",
    "\n",
    "# clean up\n",
    "plt.xlim((0.5, 2.5));plt.ylim((0,1));\n",
    "plt.xticks(np.array([1,2]),('Mixed Gamal','SCA'));\n",
    "plt.yticks(np.array([0,0.5, 1]));\n",
    "plt.ylabel('R2');\n",
    "plt.tight_layout()\n",
    "legend = plt.legend(loc = 'lower right');\n",
    "\n",
    "# # # save directory\n",
    "figDir = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/bootstraps/'\n",
    "\n",
    "# # save\n",
    "plt.savefig(figDir + monkName + '_mix_gamal_r2_dist_ind.pdf', dpi = 'figure')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change color of axis labels so we can see them in the pdf\n",
    "plt.rcParams['text.color'] = 'k'\n",
    "plt.rcParams['xtick.color'] = 'k'\n",
    "plt.rcParams['ytick.color'] = 'k'\n",
    "plt.rcParams['axes.labelcolor'] = 'k'\n",
    "\n",
    "# reshape pca reconstructions\n",
    "pcaR2_recon = np.reshape(allR2_mgamal,[-1,1],order = 'F')\n",
    "\n",
    "# plot pca results with a small amount of jitter around 1\n",
    "pcaLoc = np.random.normal(loc = 1,scale = 0.03,size = (numBoots*R_est,1))\n",
    "fig, ax = plt.subplots()\n",
    "# plot pca reconstractions across neurons and across bootstraps\n",
    "plt.plot(pcaLoc,pcaR2_recon,'o',color = (0.4,0.4,0.4),ms = 4,alpha = 0.02);\n",
    "\n",
    "# plot the mean and std of pca performance\n",
    "plt.errorbar(1,np.mean(pcaR2_recon),np.std(pcaR2_recon), uplims=1,color = 'k',lw = 3,zorder = 3,label = 'PCA')\n",
    "plt.plot(1,np.mean(pcaR2_recon),'o',color = 'k',ms = 8,zorder = 3);\n",
    "\n",
    "# now SCA\n",
    "scaR2_recon = np.reshape(allR2_sca,[-1,1],order = 'F')\n",
    "\n",
    "# get jittered position for ssa reconstructions\n",
    "scaLoc = np.random.normal(loc = 2,scale = 0.03,size = (numBoots*R_est,1))\n",
    "plt.plot(scaLoc,scaR2_recon,'o',color = 'purple',ms = 4, alpha = 0.02);\n",
    "\n",
    "# plot the mean and std of ssa performance\n",
    "plt.errorbar(2,np.mean(scaR2_recon),np.std(scaR2_recon), uplims=1, color = 'purple',lw = 3, zorder =3,label = 'SCA')\n",
    "plt.plot(2,np.mean(scaR2_recon),'o',color = 'purple',ms = 8,zorder=3);\n",
    "\n",
    "# clean up\n",
    "plt.xlim((0.5, 2.5));plt.ylim((0,1.05));\n",
    "plt.xticks(np.array([1,2]),('Mixed Gamal','SSA'));\n",
    "plt.yticks(np.array([0,0.5, 1]));\n",
    "plt.ylabel('R2');\n",
    "plt.tight_layout()\n",
    "legend = plt.legend(loc = 'lower right');\n",
    "\n",
    "# # # save directory\n",
    "figDir = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/bootstraps/'\n",
    "\n",
    "# # save\n",
    "plt.savefig(figDir + monkName + '_mix_gamal_r2_dist_all.pdf', dpi ='figure')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color theme: purple\n",
    "colorIdx = np.arange(0.55,1,0.4/8)\n",
    "\n",
    "# define ssa colors\n",
    "ssa_cMap = sns.cubehelix_palette(rot = 0.2,dark = 0.15, light = 0.8,as_cmap = True,gamma = 1.1)\n",
    "ssa_cMap = ssa_cMap(colorIdx)\n",
    "\n",
    "# define pca colors\n",
    "pca_cMap = sns.cubehelix_palette(rot = 0.2,dark = 0.15, light = 0.8,as_cmap = True,gamma = 0.7,hue = 0.3)\n",
    "pca_cMap = pca_cMap(colorIdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figDir = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/bootstraps/'\n",
    "#plot bootstraping distribution of MEAN R2\n",
    "# plt.title(\"Gamal - SCA/PCA mean R2, boots n=\" + str(100))\n",
    "plt.hist(np.mean(maxR2_mgamal, axis = 1), bins=np.arange(0.5, 1.05, 0.05),color=pca_cMap[0,:],alpha = .7, label = 'Mixed Gamal') \n",
    "plt.hist(np.mean(maxR2_sca, axis = 1), bins=np.arange(0.5, 1.05, 0.05),color=ssa_cMap[0,:],alpha = .7,label = 'SCA') \n",
    "# add a legend\n",
    "legend = plt.legend();\n",
    "plt.xlabel('R2');\n",
    "plt.ylabel('Frequency');\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkName + '_mix_gamal_meanr2.pdf', dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot bootstraping distribution of MEDIAN R2\n",
    "# plt.title(\"Gamal - SCA/PCA median R2, boots n=\" + str(100))\n",
    "plt.hist(np.median(maxR2_mgamal, axis = 1), bins=np.arange(0.5, 1.05, 0.05),color=pca_cMap[0,:],alpha = .7, label = 'Mixed Gamal') \n",
    "plt.hist(np.median(maxR2_sca, axis = 1), bins=np.arange(0.5, 1.05, 0.05),color=ssa_cMap[0,:],alpha = .7,label = 'SCA') \n",
    "plt.xlabel('R2');\n",
    "plt.ylabel('Frequency');\n",
    "# add a legend\n",
    "legend = plt.legend();\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkName + '_mix_gamal_medianr2.pdf', dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamal_allspec_r2meanDiff_sca = [np.mean(allR2_sca[i,:])-np.mean(maxR2_sca[i,:]) for i in range(100)]\n",
    "gamal_allspec_r2meanDiff_pca = [np.mean(allR2_mgamal[i,:])-np.mean(maxR2_mgamal[i,:]) for i in range(100)]\n",
    "pca_sca_diff = np.array(gamal_allspec_r2meanDiff_pca) - np.array(gamal_allspec_r2meanDiff_sca)\n",
    "\n",
    "# plt.title(\"Gamal - SCA minus PCA mean R2, boots n=\" + str(100))\n",
    "plt.hist(gamal_allspec_r2meanDiff_sca, bins=np.arange(-0.5, 0.55, 0.05),color=ssa_cMap[0,:],alpha = .7, label = 'SCA')\n",
    "plt.hist(gamal_allspec_r2meanDiff_pca, bins=np.arange(-0.5, 0.55, 0.05),color=pca_cMap[0,:],alpha = .7, label = 'Mixed Gamal')\n",
    "plt.legend()\n",
    "plt.axvline(x = 0, linestyle =\"--\",color='k')\n",
    "prop = sum(1 for i in pca_sca_diff if i > 0)/len(pca_sca_diff)\n",
    "plt.text(.3, 15, str(prop*100) +'%', style='italic')\n",
    "plt.xlabel('R2 difference');\n",
    "plt.ylabel('Frequency');\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkName + '_mix_gamal_allMeanDiff.pdf', dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamal_allspec_r2medianDiff_sca = [np.median(allR2_sca[i,:])-np.median(maxR2_sca[i,:]) for i in range(100)]\n",
    "gamal_allspec_r2medianDiff_pca = [np.median(allR2_mgamal[i,:])-np.median(maxR2_mgamal[i,:]) for i in range(100)]\n",
    "pca_sca_diff = np.array(gamal_allspec_r2medianDiff_pca) - np.array(gamal_allspec_r2medianDiff_sca)\n",
    "\n",
    "# plt.title(\"Gamal - SCA minus PCA mean R2, boots n=\" + str(100))\n",
    "plt.hist(gamal_allspec_r2medianDiff_sca, bins=np.arange(-0.5, 0.55, 0.05),color=ssa_cMap[0,:],alpha = .7, label = 'SCA')\n",
    "plt.hist(gamal_allspec_r2medianDiff_pca, bins=np.arange(-0.5, 0.55, 0.05),color=pca_cMap[0,:],alpha = .7, label = 'Mixed Gamal')\n",
    "plt.legend()\n",
    "plt.axvline(x = 0, linestyle =\"--\",color='k')\n",
    "prop = sum(1 for i in pca_sca_diff if i > 0)/len(pca_sca_diff)\n",
    "plt.text(.3, 15, str(prop*100) +'%', style='italic')\n",
    "plt.xlabel('R2 difference');\n",
    "plt.ylabel('Frequency');\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkName + '_mix_gamal_allMedianDiff.pdf', dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot SCA/PCA difference in MEAN R2\n",
    "gamal_r2meanDiff = [np.mean(maxR2_sca[i,:])-np.mean(maxR2_mgamal[i,:]) for i in range(100)]\n",
    "# plt.title(\"Gamal - SCA minus PCA mean R2, boots n=\" + str(100))\n",
    "plt.hist(gamal_r2meanDiff, bins=np.arange(-0.5, 0.55, 0.05),color=pca_cMap[0,:],alpha = .7)\n",
    "plt.axvline(x = 0, linestyle =\"--\",color='k')\n",
    "prop = sum(1 for i in gamal_r2meanDiff if i > 0)/len(gamal_r2meanDiff)\n",
    "plt.text(.3, 15, str(prop*100) +'%', style='italic')\n",
    "plt.xlabel('R2 difference');\n",
    "plt.ylabel('Frequency');\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkName + '_mix_gamal_meanr2diff.pdf', dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot SCA/PCA difference in MEDIAN R2\n",
    "gamal_r2medianDiff = [np.median(maxR2_sca[i,:])-np.median(maxR2_mgamal[i,:]) for i in range(100)]\n",
    "# plt.title(\"Gamal - SCA minus PCA median R2, boots n=\" + str(100))\n",
    "plt.hist(gamal_r2medianDiff, bins=np.arange(-0.5, 0.55, 0.05),color=pca_cMap[0,:],alpha = .7)\n",
    "plt.axvline(x = 0, linestyle =\"--\",color='k')\n",
    "prop = sum(1 for i in gamal_r2medianDiff if i >= 0)/len(gamal_r2medianDiff)\n",
    "plt.text(.3, 15, str(prop*100) +'%', style='italic')\n",
    "plt.xlabel('R2 difference');\n",
    "plt.ylabel('Frequency');\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkName + '_mix_gamal_medianr2diff.pdf', dpi = 'figure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Gamal results in bootstraps\n",
    "monkName = 'Balboa'\n",
    "load_folder='/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/'\n",
    "gamal_data=io.loadmat(load_folder + monkName + '_gamalLoadings.mat')\n",
    "# gamal_data=io.loadmat(load_folder + monkName + '_MIX2_gamalLoadings.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defind prep, move, and post projections\n",
    "gamal_PrepProj = gamal_data['prepProj_list'][:,:,None]\n",
    "gamal_MoveProj = gamal_data['moveProj_list'][:,:,None]\n",
    "gamal_PostProj = gamal_data['postProj_list'][:,:,None]\n",
    "# gamal_MixProj = gamal_data['mixProj_list'][:,:,None]\n",
    "print(gamal_PrepProj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load PCA and SCA results\n",
    "load_folder='/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/original_fit/'\n",
    "pca_latents=io.loadmat(load_folder + monkName + '_pca_original_dim8.mat')['latents']\n",
    "print(pca_latents.shape)\n",
    "sca_latents=io.loadmat(load_folder + monkName + '_sca_original_dim8.mat')['latents']\n",
    "print(sca_latents.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_est = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define some new colormaps\n",
    "# fraction of colormap to use\n",
    "colorIdx = np.arange(0.55,1,0.4/8)\n",
    "\n",
    "# define prep colors\n",
    "prep_cMap = sns.cubehelix_palette(start = 2,rot = 0,dark = 0.15, light = 0.8,as_cmap = True,gamma = 1.1)\n",
    "prep_cMap = prep_cMap(colorIdx)\n",
    "\n",
    "# move colors\n",
    "move_cMap = sns.cubehelix_palette(start = 2.35,rot = 0,dark = 0.15, light = 0.8,as_cmap = True,gamma = 0.7)\n",
    "move_cMap = move_cMap(colorIdx)\n",
    "\n",
    "# posture colors\n",
    "post_cMap = sns.cubehelix_palette(start = 2.8,rot = 0,dark = 0.15, light = 0.8,as_cmap = True,gamma = 0.7)\n",
    "post_cMap = post_cMap(colorIdx)\n",
    "\n",
    "# plot colors\n",
    "plt.figure(figsize = (5,5));\n",
    "plt.subplot(311);\n",
    "for i in np.arange(8):\n",
    "    plt.plot(np.arange(0,10)*i,color = prep_cMap[i,:],linewidth = 8);\n",
    "\n",
    "plt.subplot(312);\n",
    "for i in np.arange(8):\n",
    "    plt.plot(np.arange(0,10)*i,color = move_cMap[i,:],linewidth = 8);\n",
    "\n",
    "plt.subplot(313);\n",
    "for i in np.arange(8):\n",
    "    plt.plot(np.arange(0,10)*i,color = post_cMap[i,:],linewidth = 8);\n",
    "\n",
    "# concatenate colormaps\n",
    "prep_cMap = prep_cMap[:,:,None]\n",
    "move_cMap = move_cMap[:,:,None]\n",
    "post_cMap = post_cMap[:,:,None]\n",
    "\n",
    "g_cMap = np.concatenate((prep_cMap, move_cMap, post_cMap),axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gProj = np.concatenate((gamal_PrepProj,gamal_MixProj),axis = -1)\n",
    "print(gProj.shape)\n",
    "gProj_reshaped = np.hstack([gProj[:,:4,0], gProj[:,:4,1]])\n",
    "gProj_reshaped.shape\n",
    "gProj_plot = np.reshape(gProj_reshaped,(trlDur,8,R_est),order='F')\n",
    "gProj_plot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gProj = np.concatenate((gamal_PrepProj, gamal_PostProj, gamal_MoveProj),axis = -1)\n",
    "print(gProj.shape)\n",
    "gProj_reshaped = np.hstack([gProj[:,:3,0], gProj[:,:2,1], gProj[:,:3,2]])\n",
    "gProj_reshaped.shape\n",
    "gProj_plot = np.reshape(gProj_reshaped,(trlDur,8,R_est),order='F')\n",
    "gProj_plot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "g_cMap  = ['#00d01e', '#00ba22', '#00a426', '#008e2a', '#00782e', '#006232', '#004c36', '#00363a']\n",
    "# g_cMap  = ['#e8a048', '#d48b3f', '#c07737', '#ac632e', '#984e26', '#843a1d', '#702615', '#5c120d']\n",
    "\n",
    "# define some useful time points\n",
    "tgt_idx=20\n",
    "move_idx=77\n",
    "ret_idx=200\n",
    "# range for y axis\n",
    "yRange = [-1.8,1.8]\n",
    "fig = make_subplots(rows=R_est,cols = 1,shared_xaxes = True,vertical_spacing = 0)\n",
    "\n",
    "for ii in range(R_est):\n",
    "\n",
    "    for jj in range(numConds):\n",
    "        latTrace = go.Scatter(y = gProj_plot[:,jj,ii], line = go.scatter.Line(color = g_cMap[jj],width = 1),showlegend = False)\n",
    "        fig.add_trace(latTrace,row = ii+1,col=1)\n",
    "        if ii == (R_est-1):\n",
    "            fig.add_vline(x = tgt_idx,row = ii+1,col = 1, line_color = 'black')\n",
    "            fig.add_vline(x = move_idx,row = ii+1,col = 1, line_color = 'black')\n",
    "            fig.add_vline(x = ret_idx,row = ii+1,col = 1, line_color = 'black')\n",
    "\n",
    "            #\n",
    "    # add a vertical line for scale\n",
    "    scaleLine = go.Scatter(x = [-5,-5],y = [-0.4,0.4],showlegend = False,mode = 'lines',\n",
    "                            line = go.scatter.Line(color = 'black',width = 3))\n",
    "    fig.add_trace(scaleLine,row = ii+1,col = 1)\n",
    "\n",
    "\n",
    "fig.update_layout(height = 1000,width =500,title = 'Gamal ' + monkName,title_font_color = 'black',\n",
    "                  paper_bgcolor = 'white',\n",
    "                  plot_bgcolor = 'white')\n",
    "fig.update_yaxes(showgrid = False,zeroline = False,visible = False,range = yRange)\n",
    "fig.update_xaxes(color = 'black',showgrid = False,zeroline = False,visible = False)\n",
    "fig.update_xaxes(color = 'black',showgrid = False,zeroline = False,\n",
    "                 ticks = 'outside',tickvals = [0,50],ticktext = ['0','500'],visible = True,row = R_est,col = 1)\n",
    "\n",
    "\n",
    "# save\n",
    "figDir = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/'\n",
    "fig.write_image(figDir + monkName + 'Gamal_' + str(R_est) + 'dims.pdf')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot Gamal projections\n",
    "\n",
    "# gProj = np.concatenate((gamal_PrepProj,gamal_MoveProj,gamal_PostProj),axis = -1)\n",
    "gProj = np.concatenate((gamal_PrepProj,gamal_MixProj),axis = -1)\n",
    "\n",
    "#Get indices of each trial\n",
    "T=data_downsamp.shape[2] #Length of time per condition\n",
    "trs=np.arange(0,8)\n",
    "t_idxs=[np.arange(T*tr,T*(tr+1)) for tr in trs]\n",
    "\n",
    "# define some useful time points\n",
    "tgt_idx=20\n",
    "move_idx=77\n",
    "ret_idx=200\n",
    "\n",
    "# change color of axis labels so we can see them in the pdf\n",
    "plt.rcParams['text.color'] = 'k'\n",
    "plt.rcParams['xtick.color'] = 'k'\n",
    "plt.rcParams['ytick.color'] = 'k'\n",
    "plt.rcParams['axes.labelcolor'] = 'k'\n",
    "\n",
    "# fig,ax=plt.subplots(12,3,figsize=(15,20))\n",
    "fig,ax=plt.subplots(12,2,figsize=(10,20))\n",
    "# for E in range(3):\n",
    "for E in range(2):\n",
    "    for i in range(12):\n",
    "        for j in range(len(trs)):\n",
    "\n",
    "            ax[i,E].plot(gProj[:,i,E][t_idxs[j]],linewidth=2.25,color=g_cMap[j,:,E])\n",
    "\n",
    "            ax[i,E].plot([tgt_idx,tgt_idx],[-100,100],'gray',linewidth=.5)\n",
    "            ax[i,E].plot([move_idx,move_idx],[-100,100],'k',linewidth=.5)\n",
    "            ax[i,E].plot([ret_idx,ret_idx],[-100,100],'k',linewidth=.5)\n",
    "\n",
    "            ax[i,E].set_xlim([0,T+1])\n",
    "            ax[i,E].set_ylim([-2, 2])\n",
    "\n",
    "            if i<12-1:\n",
    "                ax[i,E].set_xticks([])\n",
    "            else:\n",
    "                ax[i,E].set_xlabel('Time (10ms bins)')\n",
    "\n",
    "            ax[i,E].set_yticks([])\n",
    "            ax[i,E].set_ylabel('Dim. '+str(i+1))\n",
    "\n",
    "ax[0,0].set_title('Preparation Projections')\n",
    "ax[0,1].set_title('Mix Projections')\n",
    "# ax[0,1].set_title('Move Projections')\n",
    "# ax[0,2].set_title('Posture Projections')\n",
    "# save figure\n",
    "\n",
    "# save directory\n",
    "figDir = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/'\n",
    "\n",
    "# save\n",
    "# plt.savefig(figDir + monkName + '_gamalProj.pdf',dpi = 'figure')\n",
    "plt.savefig(figDir + monkName + '_MIX2_gamalProj.pdf',dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only take top 4 Gamal latents from each behavior\n",
    "top4_gProj = np.concatenate((gamal_PrepProj[:,:4,:],gamal_MoveProj[:,:4,:],gamal_PostProj[:,:4,:]),axis = -1)\n",
    "print(top4_gProj.shape)\n",
    "top4_gProj = top4_gProj.reshape(top4_gProj.shape[0],-1)\n",
    "print(top4_gProj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each bootstrap, pull out random 4 gamal latents to regress to pca/sca latents\n",
    "\n",
    "# number of bootstraps\n",
    "numBoots = 100\n",
    "\n",
    "# initialize vector to hold R2\n",
    "randR2_pca = np.zeros((numBoots,R_est))\n",
    "randR2_sca = np.zeros((numBoots,R_est))\n",
    "\n",
    "# cycle through bootstrap repetitions\n",
    "for n in range(numBoots):\n",
    "    # draw 4 latents with replacement\n",
    "    numL = 8\n",
    "    nIdx = np.random.choice(top4_gProj.shape[1],numL,replace=False)\n",
    "\n",
    "    # pull out PCA bootstrap latents\n",
    "    Y = pca_latents\n",
    "\n",
    "    # pull out all gamal projections\n",
    "    X = top4_gProj[:,nIdx]\n",
    "\n",
    "    # regress\n",
    "    B = np.linalg.inv(X.T@X) @ X.T @ Y\n",
    "\n",
    "    # reconstruct Y \n",
    "    Y_hat = X @ B\n",
    "\n",
    "    # calculate R2\n",
    "    ss_tot = np.sum((Y - np.mean(Y,axis = 0))**2, axis = 0)\n",
    "    ss_res = np.sum((Y - Y_hat)**2,axis = 0)\n",
    "    randR2_pca[n,:] = 1 - (ss_res/ss_tot)\n",
    "        \n",
    "    # pull out SCA bootstrap latents\n",
    "    Y = sca_latents\n",
    "\n",
    "    # pull out all gamal projections\n",
    "    X = top4_gProj[:,nIdx]\n",
    "\n",
    "    # regress\n",
    "    B = np.linalg.inv(X.T@X) @ X.T @ Y\n",
    "\n",
    "    # reconstruct Y \n",
    "    Y_hat = X @ B\n",
    "\n",
    "    # calculate R2\n",
    "    ss_tot = np.sum((Y - np.mean(Y,axis = 0))**2, axis = 0)\n",
    "    ss_res = np.sum((Y - Y_hat)**2,axis = 0)\n",
    "    randR2_sca[n,:] = 1 - (ss_res/ss_tot)\n",
    "\n",
    "#print first bootstrap's max R2's\n",
    "print(randR2_pca[0])\n",
    "print(randR2_sca[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change color of axis labels so we can see them in the pdf\n",
    "plt.rcParams['text.color'] = 'k'\n",
    "plt.rcParams['xtick.color'] = 'k'\n",
    "plt.rcParams['ytick.color'] = 'k'\n",
    "plt.rcParams['axes.labelcolor'] = 'k'\n",
    "\n",
    "# reshape pca reconstructions\n",
    "pcaR2_recon = np.reshape(randR2_pca,[-1,1],order = 'F')\n",
    "\n",
    "# plot pca results with a small amount of jitter around 1\n",
    "pcaLoc = np.random.normal(loc = 1,scale = 0.03,size = (numBoots*R_est,1))\n",
    "\n",
    "# plot pca reconstractions across neurons and across bootstraps\n",
    "plt.plot(pcaLoc,pcaR2_recon,'o',color = (0.4,0.4,0.4),ms = 4,alpha = 0.02);\n",
    "\n",
    "# plot the mean and std of pca performance\n",
    "plt.errorbar(1,np.mean(pcaR2_recon),np.std(pcaR2_recon),color = 'k',lw = 3,zorder = 3,label = 'PCA')\n",
    "plt.plot(1,np.mean(pcaR2_recon),'o',color = 'k',ms = 8,zorder = 3);\n",
    "\n",
    "# now SCA\n",
    "scaR2_recon = np.reshape(randR2_sca,[-1,1],order = 'F')\n",
    "\n",
    "# get jittered position for ssa reconstructions\n",
    "scaLoc = np.random.normal(loc = 2,scale = 0.03,size = (numBoots*R_est,1))\n",
    "plt.plot(scaLoc,scaR2_recon,'o',color = 'purple',ms = 4, alpha = 0.02);\n",
    "\n",
    "# plot the mean and std of ssa performance\n",
    "plt.errorbar(2,np.mean(scaR2_recon),np.std(scaR2_recon) ,color = 'purple',lw = 3, zorder =3,label = 'SCA')\n",
    "plt.plot(2,np.mean(scaR2_recon),'o',color = 'purple',ms = 8,zorder=3);\n",
    "\n",
    "# clean up\n",
    "plt.xlim((0.5, 2.5));plt.ylim((0,1));\n",
    "plt.xticks(np.array([1,2]),('PCA','SSA'));\n",
    "plt.yticks(np.array([0,0.5, 1]));\n",
    "plt.ylabel('R2');\n",
    "plt.tight_layout()\n",
    "legend = plt.legend(loc = 'lower right');\n",
    "\n",
    "# # # save directory\n",
    "figDir = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/bootstraps/'\n",
    "\n",
    "# # save\n",
    "# plt.savefig(figDir + monkName + '_gamal_r2_dist.pdf', dpi = 'figure')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is held-out condition still interpretable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_est = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pca_L1 = np.zeros((numConds,1))\n",
    "all_sca_L1 = np.zeros((numConds,1))\n",
    "\n",
    "# load original model weights\n",
    "load_folder='/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/original_fit/'\n",
    "w_pca =io.loadmat(load_folder + monkName + '_pca_original_dim8.mat')\n",
    "w_sca =io.loadmat(load_folder + monkName + '_sca_original_dim8.mat')\n",
    "\n",
    "for i in range(0,numConds):\n",
    "    # one condition a time\n",
    "    holdOutTimes = np.tile(np.arange(trlDur),(1,numConds)).T.flatten()\n",
    "    holdOutTimes[i*trlDur:(i+1)*trlDur] = 9999\n",
    "    allTimes = np.arange(0,trlDur)\n",
    "    holdOutMask = np.in1d(holdOutTimes,allTimes)\n",
    "    fit_d = fit_data[~holdOutMask,:]\n",
    "    print(fit_d.shape)\n",
    "    all_pca_L1[i] = np.sum(abs(fit_d @ w_pca['U']))/trlDur \n",
    "    all_sca_L1[i] = np.sum(abs(fit_d @ w_sca['U'] + w_sca['U_bias']))/trlDur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Initialize arrays to hold data \n",
    "train_pca_L1 = np.zeros((numConds,1))\n",
    "train_sca_L1 = np.zeros((numConds,1))\n",
    "test_pca_L1 = np.zeros((numConds,1))\n",
    "test_sca_L1 = np.zeros((numConds,1))\n",
    "\n",
    "for i in range(0,numConds):\n",
    "    # Hold out one condition a time\n",
    "    holdOutTimes = np.tile(np.arange(trlDur),(1,numConds)).T.flatten()\n",
    "    holdOutTimes[i*trlDur:(i+1)*trlDur] = 9999\n",
    "    allTimes = np.arange(0,trlDur)\n",
    "    holdOutMask = np.in1d(holdOutTimes,allTimes)\n",
    "    \n",
    "    fit_d = fit_data[holdOutMask,:]\n",
    "    s_weights = get_sample_weights(fit_d)\n",
    "    \n",
    "    # Get the train period mask for training conditions\n",
    "    trainTimes = np.arange(20,230)\n",
    "    holdOutTimes = np.delete(holdOutTimes,np.s_[i*trlDur:(i+1)*trlDur])\n",
    "    holdOutMask_train = np.in1d(holdOutTimes,trainTimes)\n",
    "\n",
    "    # Get ground truths of held-out condition\n",
    "    Y = fit_data[i*trlDur:(i+1)*trlDur]\n",
    "    \n",
    "    # run weighted pca, get L1 for training and testing conditions\n",
    "    pca_uEst, pca_vEst = weighted_pca(fit_d[holdOutMask_train,:],R_est,s_weights[holdOutMask_train])\n",
    "    train_pca_L1[i] =  np.sum(abs(fit_d @ pca_uEst))/((numConds - 1)*trlDur) \n",
    "    test_pca_L1[i] = np.sum(abs(Y @ pca_uEst))/ trlDur \n",
    "       \n",
    "    # run sca\n",
    "    m, lt, y, lo = fit_ssa(X=fit_d[holdOutMask_train,:],R=R_est,sample_weight=s_weights[holdOutMask_train],orth = False)\n",
    "    sca_lat = fit_d @ m.fc1.weight.detach().numpy().T + m.fc1.bias.detach().numpy()\n",
    "    train_sca_L1[i] =  np.sum(abs(fit_d @ m.fc1.weight.detach().numpy().T + m.fc1.bias.detach().numpy()))/ ((numConds - 1)*trlDur) \n",
    "    test_sca_L1[i] = np.sum(abs(Y @ m.fc1.weight.detach().numpy().T + m.fc1.bias.detach().numpy())) / trlDur \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraction of colormap to use\n",
    "colorIdx = np.arange(0.55,1,0.4/8)\n",
    "\n",
    "# define ssa colors\n",
    "sca_cMap = sns.cubehelix_palette(start = 0.1,rot = 0.6,dark = 0.15, light = 0.8,as_cmap = True,gamma = 1.1)\n",
    "sca_cMap = sca_cMap(colorIdx)\n",
    "\n",
    "# define pca colors\n",
    "pca_cMap = sns.cubehelix_palette(start = 0.1,rot = 0.6,dark = 0.15, light = 0.8,as_cmap = True,gamma = 0.7,hue = 0.3)\n",
    "pca_cMap = pca_cMap(colorIdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "d = all_pca_L1.flatten() - all_sca_L1.flatten()\n",
    "res = wilcoxon(d, alternative = 'greater')\n",
    "\n",
    "fig, (ax1, ax3) = plt.subplots(1, 2, figsize=(7,5))\n",
    "fig.suptitle(monkName)\n",
    "# fig.suptitle('Sparsity in training and holding conditions')\n",
    "ax1.set_title('Original Model ' + str(int(res.pvalue*10000000)/10000000), fontsize = 13)\n",
    "for i in range(numConds):\n",
    "    c = plt.cm.Dark2(i)\n",
    "    ax1.plot(0, all_pca_L1[i],'o',color=c)\n",
    "    ax1.plot(1, all_sca_L1[i],'o',color=c)\n",
    "    ax1.plot([0,1],[all_pca_L1[i],all_sca_L1[i]],color=c)\n",
    "ax1.bar(['PCA','SCA'], [np.mean(all_pca_L1), np.mean(all_sca_L1)], color=[pca_cMap[0,:], sca_cMap[0,:]])\n",
    "ax1.set_ylabel('L1 loss')\n",
    "ax1.set_ylim([0, 2.2])\n",
    "\n",
    "\n",
    "# ax2.set_title('Training conditions', fontsize = 16)\n",
    "# ax2.plot(np.repeat(0, numConds), train_pca_L1,'o',color='k',alpha = 0.2)\n",
    "# ax2.plot(np.repeat(1, numConds), train_sca_L1,'o',color='k',alpha = 0.2)\n",
    "# for i in range(numConds):\n",
    "#     ax2.plot([0,1],[train_pca_L1[i],train_sca_L1[i]],color='k',alpha = 0.2)\n",
    "# ax2.bar(['PCA','SCA'], [np.mean(train_pca_L1), np.mean(train_sca_L1)], color=[pca_cMap[0,:], sca_cMap[0,:]])\n",
    "# ax2.set_yticks([])\n",
    "# ax2.set_ylim([0, 2])\n",
    "\n",
    "d = test_pca_L1.flatten() - test_sca_L1.flatten()\n",
    "res = wilcoxon(d, alternative = 'greater')\n",
    "ax3.set_title('Testing conditions ' + str(int(res.pvalue*10000000)/10000000), fontsize = 13)\n",
    "for i in range(numConds):\n",
    "    c = c = plt.cm.Dark2(i)\n",
    "    ax3.plot(0, test_pca_L1[i],'o',color=c)\n",
    "    ax3.plot(1, test_sca_L1[i],'o',color=c)\n",
    "    ax3.plot([0,1],[test_pca_L1[i],test_sca_L1[i]],color=c)\n",
    "ax3.bar(['PCA','SCA'], [np.mean(test_pca_L1), np.mean(test_sca_L1)],color=[pca_cMap[0,:], sca_cMap[0,:]])\n",
    "ax3.set_ylim([0, 2.2])\n",
    "ax3.set_yticks([])\n",
    "\n",
    "figDir = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/holdout/'\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkName + '_holdOut1_L1.pdf', dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA/SCA R2 as function of R_est, holding out both neurons and conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sses_pred(y_test,y_test_pred):\n",
    "    sse=np.sum((y_test_pred-y_test)**2,axis=0)\n",
    "    return sse\n",
    "\n",
    "def get_sses_mean(y_test):\n",
    "    y_mean=np.mean(y_test,axis=0)\n",
    "    sse_mean=np.sum((y_test-y_mean)**2,axis=0)\n",
    "    return sse_mean\n",
    "def r2_norm(y,y_pred):\n",
    "    return 1-np.sum((y-y_pred)**2)/np.sum((y-np.mean(y))**2)## SCA R2 as function of lam_sparse, holding out both neurons and conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y2=np.copy(fit_data) #copy neural data\n",
    "num_nrns=Y2.shape[1]\n",
    "\n",
    "ks= np.append(list(range(1, 10, 1)),list((range(10, 51, 5)))) #R_est to loop across\n",
    "print(ks)\n",
    "\n",
    "num_cv_neurons = 10 #(1/num_cv_neurons)% neurons are held out each time; 4->25%, 10->10%\n",
    "num_cv_conds = 8 #8/num_cv_conds are held out each time; 2->4 conds, 4->2 conds, 8->1 cond\n",
    "\n",
    "#initialize arrays to hold r2\n",
    "holdOut_rest_pca_r2=np.zeros((len(ks),num_nrns))\n",
    "holdOut_rest_sca_r2=np.zeros((len(ks),num_nrns))\n",
    "holdOut_rest_pca_mr2 = np.zeros((len(ks),1))\n",
    "holdOut_rest_sca_mr2 = np.zeros((len(ks),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save predictions across condition splitting\n",
    "Y_pca_pred_rest = np.zeros((len(ks),numConds*trlDur, numN)) \n",
    "Y_sca_pred_rest = np.zeros((len(ks),numConds*trlDur, numN))\n",
    "## Loop R_est\n",
    "for k,r_est in enumerate(ks):\n",
    "    ## Loop neuron splitting\n",
    "    kf2 = KFold(n_splits=num_cv_neurons,shuffle=True)   \n",
    "    for train_index, test_index in kf2.split(np.arange(num_nrns)):\n",
    "\n",
    "        train_nrns=np.arange(num_nrns)[train_index]\n",
    "        test_nrns=np.arange(num_nrns)[test_index]\n",
    "        \n",
    "        s_weight=get_sample_weights(Y2)\n",
    "        Y2_train = Y2[trainMask,:]\n",
    "        \n",
    "        #Fit PCA to all time on subset of neurons\n",
    "        u_est,v_est = weighted_pca(Y2_train[:,train_nrns],r_est,s_weight[trainMask])\n",
    "        pca_lat = Y2[:,train_nrns]@u_est\n",
    "        #Fit SCA\n",
    "        if r_est == 1:\n",
    "            m, lt, y, lo = fit_ssa(X=Y2_train[:,train_nrns],R=r_est,orth = False,sample_weight=s_weight[trainMask],lam_orthog=0)\n",
    "        else:\n",
    "            m, lt, y, lo = fit_ssa(X=Y2_train[:,train_nrns],R=r_est,orth = False,sample_weight=s_weight[trainMask])\n",
    "        sca_lat = Y2[:,train_nrns]@ m.fc1.weight.detach().numpy().T + m.fc1.bias.detach().numpy()\n",
    "    \n",
    "        ## Loop condition splitting\n",
    "        kf3 = KFold(n_splits=num_cv_conds,shuffle=True)       \n",
    "        for train_idx, test_idx in kf3.split(np.arange(numConds)):\n",
    "            #get time ranges of train and test conditions\n",
    "            ranges = []\n",
    "            for i, train_cond in enumerate(train_idx):\n",
    "                ranges.append(list(range(train_cond*trlDur, (train_cond+1)*trlDur)))\n",
    "            train_time = sum(ranges, [])\n",
    "            test_time = np.setdiff1d(range(0, numConds*trlDur), train_time)\n",
    "            \n",
    "            Y2_test_nrns = Y2[:,test_nrns]\n",
    "            y_test_train_time = Y2_test_nrns[train_time,:]\n",
    "            y_test_test_time = Y2_test_nrns[test_time,:]\n",
    "            \n",
    "            #PCA\n",
    "            latent_train_time = pca_lat[train_time, :]\n",
    "            latent_test_time = pca_lat[test_time, :]\n",
    "           \n",
    "            #Fit link function to training neurons during test time\n",
    "            lr=LinearRegression()\n",
    "            lr.fit(latent_train_time,y_test_train_time)\n",
    "\n",
    "            #Get predictions of testing neurons during test time\n",
    "            pca_pred=lr.predict(latent_test_time)\n",
    "                            \n",
    "            #SCA\n",
    "            latent_train_time = sca_lat[train_time, :]\n",
    "            latent_test_time = sca_lat[test_time, :]\n",
    "            \n",
    "            #Fit link function to training neurons during test time\n",
    "            lr=LinearRegression()\n",
    "            lr.fit(latent_train_time,y_test_train_time)\n",
    "\n",
    "            #Get predictions of testing neurons during test time\n",
    "            sca_pred=lr.predict(latent_test_time)\n",
    "            \n",
    "            #Save predictions to match neuron and time sequences in original data\n",
    "            for j, test_nrn in enumerate(test_nrns):\n",
    "                for c, test_cond in enumerate(test_idx):\n",
    "                    Y_pca_pred_rest[k,test_cond*trlDur:(test_cond+1)*trlDur,test_nrn] = pca_pred[c*trlDur:(c+1)*trlDur,j]\n",
    "                    Y_sca_pred_rest[k,test_cond*trlDur:(test_cond+1)*trlDur,test_nrn] = sca_pred[c*trlDur:(c+1)*trlDur,j]\n",
    "        \n",
    "        #Calculate R2 for each neuron \n",
    "        for nrn in range(num_nrns):            \n",
    "            holdOut_rest_pca_r2[k,nrn] = r2_norm(Y2[:,nrn],Y_pca_pred_rest[k,:,nrn])\n",
    "            holdOut_rest_sca_r2[k,nrn] = r2_norm(Y2[:,nrn],Y_sca_pred_rest[k,:,nrn])\n",
    "    \n",
    "    # Calculate multivariate R2 for concatenated predictions\n",
    "    sses =get_sses_pred(Y2,Y_pca_pred_rest[k,:,:])\n",
    "    sses_mean=get_sses_mean(Y2)\n",
    "    holdOut_rest_pca_mr2[k] =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "    sses =get_sses_pred(Y2,Y_sca_pred_rest[k,:,:])\n",
    "    holdOut_rest_sca_mr2[k] =1-np.sum(sses)/np.sum(sses_mean)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveDir = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/holdout/'\n",
    "io.savemat(saveDir+ monkName + '_' + 'holdOut2_Rest.mat'\n",
    "           , {'pca_r2': holdOut_rest_pca_r2, 'sca_r2': holdOut_rest_sca_r2\n",
    "           , 'pca_pred':Y_pca_pred_rest, 'sca_pred':Y_sca_pred_rest\n",
    "           , 'pca_mr2': holdOut_rest_pca_mr2, 'sca_mr2': holdOut_rest_sca_mr2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_folder = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/holdout/'\n",
    "data=io.loadmat(load_folder + monkName + '_holdOut2_Rest.mat')\n",
    "Y_pca_pred_rest = data['pca_pred']\n",
    "Y_sca_pred_rest = data['sca_pred']\n",
    "holdOut_rest_pca_mr2 = data['pca_mr2']\n",
    "holdOut_rest_sca_mr2 = data['sca_mr2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdOut_rest_pca_mr2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bootstrap to get error bars\n",
    "bs_rest_pca = np.zeros((len(ks),100))\n",
    "bs_rest_sca = np.zeros((len(ks),100))\n",
    "for i in range(len(ks)):\n",
    "    for b in range(100):\n",
    "        nIdx = np.random.choice(num_nrns,num_nrns)      \n",
    "        samp_truth = Y2[:,nIdx]\n",
    "        sses_mean=get_sses_mean(samp_truth)\n",
    "        \n",
    "        pca_samp = Y_pca_pred_rest[i][:,nIdx]\n",
    "        pca_sses =get_sses_pred(samp_truth,pca_samp)\n",
    "        bs_rest_pca[i,b] =1-np.sum(pca_sses)/np.sum(sses_mean)     \n",
    "        \n",
    "        sca_samp = Y_sca_pred_rest[i][:,nIdx]\n",
    "        sca_sses =get_sses_pred(samp_truth,sca_samp)\n",
    "        bs_rest_sca[i,b] =1-np.sum(sca_sses)/np.sum(sses_mean)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change color of axis labels so we can see them in the pdf\n",
    "plt.rcParams['text.color'] = 'k'\n",
    "plt.rcParams['xtick.color'] = 'k'\n",
    "plt.rcParams['ytick.color'] = 'k'\n",
    "plt.rcParams['axes.labelcolor'] = 'k'\n",
    "\n",
    "#error bars\n",
    "plt.fill_between(ks, np.mean(bs_rest_sca,axis=1) - np.std(bs_rest_sca,axis=1), np.mean(bs_rest_sca,axis=1) + np.std(bs_rest_sca,axis=1), color='purple', alpha=0.2)\n",
    "plt.fill_between(ks, np.mean(bs_rest_pca,axis=1) - np.std(bs_rest_pca,axis=1), np.mean(bs_rest_pca,axis=1) + np.std(bs_rest_pca,axis=1), color='#888888', alpha=0.3)\n",
    "\n",
    "# plot lines as multivariate R2 for concatenated predictions\n",
    "plt.plot(ks, holdOut_rest_pca_mr2,color = 'k', label = \"PCA\",linewidth = 2, zorder = 3)\n",
    "plt.plot(ks, holdOut_rest_sca_mr2,color = 'purple', label = \"SCA\",linewidth = 2, zorder = 3)\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('number of dimensions');\n",
    "plt.ylabel('R2');\n",
    "# plt.title(\"PCA/SCA R2 in held-out condition (\"+ str(1/num_cv_neurons*100) +\"% neurons, \" + str(int(numConds/num_cv_conds)) + \" conds)\")\n",
    "# save directory\n",
    "figDir = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/holdout/'\n",
    "\n",
    "# save\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkName + '_holdOut2_Rest.pdf', dpi = 'figure')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA/SCA R2 as function of lam_sparse, holding out both neurons and conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sses_pred(y_test,y_test_pred):\n",
    "    sse=np.sum((y_test_pred-y_test)**2,axis=0)\n",
    "    return sse\n",
    "\n",
    "def get_sses_mean(y_test):\n",
    "    y_mean=np.mean(y_test,axis=0)\n",
    "    sse_mean=np.sum((y_test-y_mean)**2,axis=0)\n",
    "    return sse_mean\n",
    "def r2_norm(y,y_pred):\n",
    "    return 1-np.sum((y-y_pred)**2)/np.sum((y-np.mean(y))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# range of lambda values to test\n",
    "lambdaRange = np.logspace(-5,1,num = 10)\n",
    "print(lambdaRange)\n",
    "\n",
    "# number of tested lambdas\n",
    "numLambda = lambdaRange.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y2=np.copy(fit_data) #copy neural data\n",
    "num_nrns=Y2.shape[1]\n",
    "\n",
    "num_cv_neurons = 10 #1/num_cv_neurons% neurons are held out each time; 4->25%, 10->10%\n",
    "num_cv_conds = 8 #8/num_cv_conds are held out each time; 2->4 conds, 4->2 conds, 8->1 cond\n",
    "\n",
    "#initialize arrays to hold r2\n",
    "holdOut_lam_pca_r2=np.zeros((len(lambdaRange),num_nrns))\n",
    "holdOut_lam_sca_r2=np.zeros((len(lambdaRange),num_nrns))\n",
    "holdOut_lam_pca_mr2 = np.zeros((len(lambdaRange),1))\n",
    "holdOut_lam_sca_mr2 = np.zeros((len(lambdaRange),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save predictions across condition splitting\n",
    "Y_pca_pred_lam = np.zeros((len(lambdaRange),numConds*trlDur, numN)) \n",
    "Y_sca_pred_lam = np.zeros((len(lambdaRange),numConds*trlDur, numN))\n",
    "## Loop lam_sparse\n",
    "R_est = 8\n",
    "\n",
    "for k,lam in enumerate(lambdaRange):\n",
    "    ## Loop neuron splitting\n",
    "    kf2 = KFold(n_splits=num_cv_neurons,shuffle=True)   \n",
    "    for train_index, test_index in kf2.split(np.arange(num_nrns)):\n",
    "\n",
    "        train_nrns=np.arange(num_nrns)[train_index]\n",
    "        test_nrns=np.arange(num_nrns)[test_index]\n",
    "        \n",
    "        s_weight=get_sample_weights(Y2)\n",
    "        Y2_train = Y2[trainMask,:]\n",
    "        \n",
    "        #Fit PCA to all time on subset of neurons\n",
    "        u_est,v_est = weighted_pca(Y2_train[:,train_nrns],R_est,s_weight[trainMask])\n",
    "        pca_lat = Y2[:,train_nrns]@u_est\n",
    "        #Fit SCA\n",
    "        m, lt, y, lo = fit_ssa(X=Y2_train[:,train_nrns],R=R_est,lam_sparse = lam, orth = False,sample_weight=s_weight[trainMask])\n",
    "        sca_lat = Y2[:,train_nrns]@ m.fc1.weight.detach().numpy().T + m.fc1.bias.detach().numpy()\n",
    "    \n",
    "        ## Loop condition splitting\n",
    "        kf3 = KFold(n_splits=num_cv_conds,shuffle=True)       \n",
    "        for train_idx, test_idx in kf3.split(np.arange(numConds)):\n",
    "            #get time ranges of train and test conditions\n",
    "            ranges = []\n",
    "            for i, train_cond in enumerate(train_idx):\n",
    "                ranges.append(list(range(train_cond*trlDur, (train_cond+1)*trlDur)))\n",
    "            train_time = sum(ranges, [])\n",
    "            test_time = np.setdiff1d(range(0, numConds*trlDur), train_time)\n",
    "            \n",
    "            Y2_test_nrns = Y2[:,test_nrns]\n",
    "            y_test_train_time = Y2_test_nrns[train_time,:]\n",
    "            y_test_test_time = Y2_test_nrns[test_time,:]\n",
    "            \n",
    "            #PCA\n",
    "            latent_train_time = pca_lat[train_time, :]\n",
    "            latent_test_time = pca_lat[test_time, :]\n",
    "           \n",
    "            #Fit link function to training neurons during test time\n",
    "            lr=LinearRegression()\n",
    "            lr.fit(latent_train_time,y_test_train_time)\n",
    "\n",
    "            #Get predictions of testing neurons during test time\n",
    "            pca_pred=lr.predict(latent_test_time)\n",
    "                            \n",
    "            #SCA\n",
    "            latent_train_time = sca_lat[train_time, :]\n",
    "            latent_test_time = sca_lat[test_time, :]\n",
    "            \n",
    "            #Fit link function to training neurons during test time\n",
    "            lr=LinearRegression()\n",
    "            lr.fit(latent_train_time,y_test_train_time)\n",
    "\n",
    "            #Get predictions of testing neurons during test time\n",
    "            sca_pred=lr.predict(latent_test_time)\n",
    "            \n",
    "            #Save predictions to match neuron and time sequences in original data\n",
    "            for j, test_nrn in enumerate(test_nrns):\n",
    "                for c, test_cond in enumerate(test_idx):\n",
    "                    Y_pca_pred_lam[k,test_cond*trlDur:(test_cond+1)*trlDur,test_nrn] = pca_pred[c*trlDur:(c+1)*trlDur,j]\n",
    "                    Y_sca_pred_lam[k,test_cond*trlDur:(test_cond+1)*trlDur,test_nrn] = sca_pred[c*trlDur:(c+1)*trlDur,j]\n",
    "        \n",
    "        #Calculate R2 for each neuron \n",
    "        for nrn in range(num_nrns):            \n",
    "            holdOut_lam_pca_r2[k,nrn] = r2_norm(Y2[:,nrn],Y_pca_pred_lam[k,:,nrn])\n",
    "            holdOut_lam_sca_r2[k,nrn] = r2_norm(Y2[:,nrn],Y_sca_pred_lam[k,:,nrn])\n",
    "    \n",
    "    # Calculate multivariate R2 for concatenated predictions\n",
    "    sses =get_sses_pred(Y2,Y_pca_pred_lam[k,:,:])\n",
    "    sses_mean=get_sses_mean(Y2)\n",
    "    holdOut_lam_pca_mr2[k] =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "    sses =get_sses_pred(Y2,Y_sca_pred_lam[k,:,:])\n",
    "    holdOut_lam_sca_mr2[k] =1-np.sum(sses)/np.sum(sses_mean)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveDir = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/holdout/'\n",
    "io.savemat(saveDir+ monkName + '_' + 'holdOut2_lam.mat'\n",
    "           , {'pca_r2': holdOut_lam_pca_r2, 'sca_r2': holdOut_lam_sca_r2\n",
    "           , 'pca_pred':Y_pca_pred_lam, 'sca_pred':Y_sca_pred_lam\n",
    "           , 'pca_mr2': holdOut_lam_pca_mr2, 'sca_mr2': holdOut_lam_sca_mr2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_folder = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/holdout/'\n",
    "data=io.loadmat(load_folder + monkName + '_holdOut2_lam.mat')\n",
    "Y_pca_pred_lam = data['pca_pred']\n",
    "Y_sca_pred_lam = data['sca_pred']\n",
    "holdOut_lam_pca_mr2 = data['pca_mr2']\n",
    "holdOut_lam_sca_mr2 = data['sca_mr2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bootstrap to get error bars\n",
    "bs_lam_pca = np.zeros((len(lambdaRange),100))\n",
    "bs_lam_sca = np.zeros((len(lambdaRange),100))\n",
    "for i in range(len(lambdaRange)):\n",
    "    for b in range(100):\n",
    "        nIdx = np.random.choice(num_nrns,num_nrns)      \n",
    "        samp_truth = Y2[:,nIdx]\n",
    "        sses_mean=get_sses_mean(samp_truth)\n",
    "        \n",
    "        pca_samp = Y_pca_pred_lam[i][:,nIdx]\n",
    "        pca_sses =get_sses_pred(samp_truth,pca_samp)\n",
    "        bs_lam_pca[i,b] =1-np.sum(pca_sses)/np.sum(sses_mean)     \n",
    "        \n",
    "        sca_samp = Y_sca_pred_lam[i][:,nIdx]\n",
    "        sca_sses =get_sses_pred(samp_truth,sca_samp)\n",
    "        bs_lam_sca[i,b] =1-np.sum(sca_sses)/np.sum(sses_mean)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change color of axis labels so we can see them in the pdf\n",
    "plt.rcParams['text.color'] = 'k'\n",
    "plt.rcParams['xtick.color'] = 'k'\n",
    "plt.rcParams['ytick.color'] = 'k'\n",
    "plt.rcParams['axes.labelcolor'] = 'k'\n",
    "\n",
    "#error bars\n",
    "plt.fill_between(lambdaRange, np.mean(bs_lam_sca,axis=1) - np.std(bs_lam_sca,axis=1), np.mean(bs_lam_sca,axis=1) + np.std(bs_lam_sca,axis=1), color='purple', alpha=0.2)\n",
    "plt.fill_between(lambdaRange, np.mean(bs_lam_pca,axis=1) - np.std(bs_lam_pca,axis=1), np.mean(bs_lam_pca,axis=1) + np.std(bs_lam_pca,axis=1), color='#888888', alpha=0.3)\n",
    "\n",
    "# plot lines as multivariate R2 for concatenated predictions\n",
    "plt.plot(lambdaRange, holdOut_lam_pca_mr2,color = 'k', label = \"PCA\",linewidth = 2, zorder = 3)\n",
    "plt.plot(lambdaRange, holdOut_lam_sca_mr2,color = 'purple', label = \"SCA\",linewidth = 2, zorder = 3)\n",
    "plt.legend(loc='lower left')\n",
    "plt.xlabel('lambda sparsity');\n",
    "plt.ylabel('R2');\n",
    "# plt.title(\"PCA/SCA R2 in held-out condition (\"+ str(1/num_cv_neurons*100) +\"% neurons, \" + str(int(numConds/num_cv_conds)) + \" conds)\")\n",
    "# # # save directory\n",
    "figDir = '/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/holdout/'\n",
    "plt.xscale(\"log\")\n",
    "plt.xticks(lambdaRange)\n",
    "plt.tight_layout()\n",
    "# save\n",
    "plt.savefig(figDir + monkName + '_holdOut2_lam.pdf', dpi = 'figure')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run bootstrap results for dPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monkName = 'Balboa'\n",
    "load_folder='/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/bootstraps/'\n",
    "data=io.loadmat(load_folder + monkName + '_' + 'bootstraps_100_dim8.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_samps = data['bs_neuron_proc_activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_est = 8\n",
    "dataL,numN = fit_data.shape\n",
    "dpca_latents = np.zeros((dataL,R_est,100))\n",
    "dpca_r = np.zeros((R_est,100))\n",
    "\n",
    "for n in range(100):\n",
    "\n",
    "    X_samp = neuron_samps[:,:,n]\n",
    "    # calculate our sample weights\n",
    "    sWeights = get_sample_weights(X_samp)\n",
    "\n",
    "    X_samp_weighted = (X_samp * sWeights)\n",
    "    d_norm_w = X_samp_weighted.T.reshape([data_downsamp.shape[1],data_downsamp.shape[0], data_downsamp.shape[2]]) # data is a N x C x T tensor \n",
    "    d_norm = X_samp.T.reshape([data_downsamp.shape[1],data_downsamp.shape[0], data_downsamp.shape[2]]) # data is a N x C x T tensor \n",
    "\n",
    "    trainT = np.arange(20,230)\n",
    "    trialT = np.arange(trlDur)\n",
    "    dpcaMask = np.in1d(trialT, trainT)\n",
    "\n",
    "    dpca = dPCA.dPCA(labels='st',n_components=R_est)\n",
    "    dpca.protect = ['t']\n",
    "    dpca.fit(d_norm_w[:,:,dpcaMask])\n",
    "    dpca_lat_dict = dpca.transform(d_norm)\n",
    "    dpca_lat = dpca_lat_dict['st'].transpose(2,1,0)\n",
    "    dpca_lat = dpca_lat.reshape((dpca_lat.shape[0]*dpca_lat.shape[1],R_est),order='F')\n",
    "    # pca latents\n",
    "    dpca_latents[:,:,n] = dpca_lat\n",
    "    \n",
    "#save bootstraping results for Gamal    \n",
    "saveDir='/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/bootstraps/'\n",
    "io.savemat(saveDir+ monkName + '_' + 'bootstraps'+ '_' + str(n+1) + '_dPCALoadings.mat', {\"bs_dpca_latents\": dpca_latents})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2408, 12, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load Gamal results in bootstraps\n",
    "monkName = 'Balboa'\n",
    "load_folder='/Users/sherryan/sca/sca_analysis/bootstraps/'\n",
    "gamal_data=io.loadmat(load_folder + monkName + '_bs_100_gamalLoadings.mat')\n",
    "# defind prep, move, and post projections\n",
    "gamal_PrepProj = gamal_data['prepProj_list'][:,:,:,None]\n",
    "gamal_MoveProj = gamal_data['moveProj_list'][:,:,:,None]\n",
    "gamal_PostProj = gamal_data['postProj_list'][:,:,:,None]\n",
    "print(gamal_PrepProj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'bs_sca_latents', 'bs_pca_latents', 'bs_neuron_proc_activity', 'sca_absR', 'pca_absR', 'original_data', 'bs_neuron_index'])\n",
      "(2408, 8, 100)\n"
     ]
    }
   ],
   "source": [
    "#Load PCA and SCA bootstrapping results\n",
    "load_folder='/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/bootstraps/'\n",
    "boot_data=io.loadmat(load_folder + monkName + '_bootstraps_100_dim8.mat')\n",
    "print(boot_data.keys())\n",
    "sca_latents = boot_data['bs_sca_latents']\n",
    "pca_latents = boot_data['bs_pca_latents']\n",
    "print(pca_latents.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'mixDims_list', 'mixProj_list', 'mixWindow', 'prepDims_list', 'prepProj_list', 'prepWindow'])\n",
      "(2408, 8, 100)\n"
     ]
    }
   ],
   "source": [
    "#Load mixed Gamal bootstrapping results\n",
    "# load_folder='/Users/sherryan/glaserlab/sca_analysis_parent/sca_analysis/bootstraps/'\n",
    "boot_data=io.loadmat(load_folder + monkName + '_bs_100_MIX2_gamalLoadings.mat')\n",
    "print(boot_data.keys())\n",
    "mix_gamal_latents = np.concatenate([boot_data['mixProj_list'][:,:4,:],boot_data['prepProj_list'][:,:4,:]],axis=1)\n",
    "print(mix_gamal_latents.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'bs_dpca_latents'])\n",
      "(2408, 8, 100)\n"
     ]
    }
   ],
   "source": [
    "boot_data=io.loadmat(load_folder + monkName + '_bootstraps_100_dPCALoadings.mat')\n",
    "print(boot_data.keys())\n",
    "dpca_latents = boot_data['bs_dpca_latents']\n",
    "print(dpca_latents.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95472264 0.88342404 0.7454204  0.89014886 0.89216944 0.75926558\n",
      " 0.6771247  0.78933604]\n",
      "[0.83350744 0.86840641 0.96228745 0.76525393 0.99085112 0.85640511\n",
      " 0.93894528 0.77781262]\n",
      "[0.98593887 0.98200895 0.92019253 0.97042284 0.98926754 0.81245578\n",
      " 0.75114869 0.96539793]\n",
      "[0.58351401 0.84237911 0.71357593 0.91089938 0.78247639 0.68739894\n",
      " 0.55195786 0.5809544 ]\n"
     ]
    }
   ],
   "source": [
    "## IND BEHAV\n",
    "R_est = 8\n",
    "\n",
    "# number of bootstraps\n",
    "numBoots = gamal_PrepProj.shape[2]\n",
    "\n",
    "# initialize vector to hold R2\n",
    "# each -1 dimenision corresponds to the reconstruction R2 from the prep, move, or posture projections\n",
    "allR2_pca = np.zeros((numBoots,R_est,3))\n",
    "allR2_sca = np.zeros((numBoots,R_est,3))\n",
    "allR2_mgamal = np.zeros((numBoots,R_est,3))\n",
    "allR2_dpca = np.zeros((numBoots,R_est,3))\n",
    "\n",
    "# cycle through bootstrap repetitions\n",
    "for n in range(numBoots):\n",
    "    gProj = np.concatenate((gamal_PrepProj[:,:,n],gamal_MoveProj[:,:,n],gamal_PostProj[:,:,n]),axis = -1)\n",
    "\n",
    "    # pull out PCA bootstrap latents\n",
    "    Y = pca_latents[:,:,n]\n",
    "\n",
    "    # get B (regression weights) from prep, move, and posture projections\n",
    "    for e in np.arange(3):\n",
    "\n",
    "        # make life a bit easier and just pull out the gamal projections we want\n",
    "        X = gProj[:,:,e]\n",
    "\n",
    "        # regress\n",
    "        B = np.linalg.inv(X.T@X) @ X.T @ Y\n",
    "\n",
    "        # reconstruct Y \n",
    "        Y_hat = X @ B\n",
    "    \n",
    "        # calculate R2\n",
    "        ss_tot = np.sum((Y - np.mean(Y,axis = 0))**2, axis = 0)\n",
    "        ss_res = np.sum((Y - Y_hat)**2,axis = 0)\n",
    "        allR2_pca[n,:,e] = 1 - (ss_res/ss_tot)\n",
    "    \n",
    "    # pull out PCA bootstrap latents\n",
    "    Y = dpca_latents[:,:,n]\n",
    "\n",
    "    # get B (regression weights) from prep, move, and posture projections\n",
    "    for e in np.arange(3):\n",
    "\n",
    "        # make life a bit easier and just pull out the gamal projections we want\n",
    "        X = gProj[:,:,e]\n",
    "\n",
    "        # regress\n",
    "        B = np.linalg.inv(X.T@X) @ X.T @ Y\n",
    "\n",
    "        # reconstruct Y \n",
    "        Y_hat = X @ B\n",
    "    \n",
    "        # calculate R2\n",
    "        ss_tot = np.sum((Y - np.mean(Y,axis = 0))**2, axis = 0)\n",
    "        ss_res = np.sum((Y - Y_hat)**2,axis = 0)\n",
    "        allR2_dpca[n,:,e] = 1 - (ss_res/ss_tot)\n",
    "\n",
    "    # pull out Mixed Gamal bootstrap latents\n",
    "    Y = mix_gamal_latents[:,:,n]\n",
    "\n",
    "    # get B (regression weights) from prep, move, and posture projections\n",
    "    for e in np.arange(3):\n",
    "\n",
    "        # make life a bit easier and just pull out the gamal projections we want\n",
    "        X = gProj[:,:,e]\n",
    "\n",
    "        # regress\n",
    "        B = np.linalg.inv(X.T@X) @ X.T @ Y\n",
    "\n",
    "        # reconstruct Y \n",
    "        Y_hat = X @ B\n",
    "    \n",
    "        # calculate R2\n",
    "        ss_tot = np.sum((Y - np.mean(Y,axis = 0))**2, axis = 0)\n",
    "        ss_res = np.sum((Y - Y_hat)**2,axis = 0)\n",
    "        allR2_mgamal[n,:,e] = 1 - (ss_res/ss_tot)        \n",
    "\n",
    "    # pull out SCA bootstrap latents\n",
    "    Y = sca_latents[:,:,n]\n",
    "\n",
    "    # get B (regression weights) from prep, move, and posture projections\n",
    "    for e in np.arange(3):\n",
    "\n",
    "        # make life a bit easier and just pull out the gamal projections we want\n",
    "        X = gProj[:,:,e]\n",
    "\n",
    "        # regress\n",
    "        B = np.linalg.inv(X.T@X) @ X.T @ Y\n",
    "\n",
    "        # reconstruct Y \n",
    "        Y_hat = X @ B\n",
    " \n",
    "        # calculate R2\n",
    "        ss_tot = np.sum((Y - np.mean(Y,axis = 0))**2, axis = 0)\n",
    "        ss_res = np.sum((Y - Y_hat)**2,axis = 0)\n",
    "        allR2_sca[n,:,e] = 1 - (ss_res/ss_tot)\n",
    "\n",
    "# take max R2 for each dimension \n",
    "maxR2_mgamal = np.max(allR2_mgamal,axis = 2)\n",
    "maxR2_sca = np.max(allR2_sca,axis = 2)\n",
    "maxR2_pca = np.max(allR2_pca,axis = 2)\n",
    "maxR2_dpca = np.max(allR2_dpca,axis = 2)\n",
    "#print first bootstrap's max R2's\n",
    "print(maxR2_pca[0])\n",
    "print(maxR2_mgamal[0])\n",
    "print(maxR2_sca[0])\n",
    "print(maxR2_dpca[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.50138751 0.66294065 0.66453849 0.72465981 0.72455915 0.71324972\n",
      " 0.88342485 0.88136725]\n"
     ]
    }
   ],
   "source": [
    "## IND BEHAV (baseline: random rotations of PCA latents)\n",
    "R_est = 8\n",
    "\n",
    "# number of bootstraps\n",
    "numBoots = gamal_PrepProj.shape[2]\n",
    "\n",
    "# initialize vector to hold R2\n",
    "# each -1 dimenision corresponds to the reconstruction R2 from the prep, move, or posture projections\n",
    "allR2_pca_rot = np.zeros((numBoots,R_est,3))\n",
    "\n",
    "# cycle through bootstrap repetitions\n",
    "for n in range(numBoots):\n",
    "    gProj = np.concatenate((gamal_PrepProj[:,:,n],gamal_MoveProj[:,:,n],gamal_PostProj[:,:,n]),axis = -1)\n",
    "\n",
    "    # pull out PCA bootstrap latents\n",
    "    Y = pca_latents[:,:,n]\n",
    "    Q, _ = np.linalg.qr(np.random.randn(R_est, R_est))\n",
    "    Y_null = Y @ Q\n",
    "    Y = Y_null\n",
    "\n",
    "    # get B (regression weights) from prep, move, and posture projections\n",
    "    for e in np.arange(3):\n",
    "\n",
    "        # make life a bit easier and just pull out the gamal projections we want\n",
    "        X = gProj[:,:,e]\n",
    "\n",
    "        # regress\n",
    "        B = np.linalg.inv(X.T@X) @ X.T @ Y\n",
    "\n",
    "        # reconstruct Y \n",
    "        Y_hat = X @ B\n",
    "    \n",
    "        # calculate R2\n",
    "        ss_tot = np.sum((Y - np.mean(Y,axis = 0))**2, axis = 0)\n",
    "        ss_res = np.sum((Y - Y_hat)**2,axis = 0)\n",
    "        allR2_pca_rot[n,:,e] = 1 - (ss_res/ss_tot)\n",
    "    \n",
    "# take max R2 for each dimension \n",
    "maxR2_pca_rotate = np.max(allR2_pca_rot,axis = 2)\n",
    "#print first bootstrap's max R2's\n",
    "print(maxR2_pca_rotate[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99957727 0.999343   0.99932242 0.99839853 0.99998073 0.9985102\n",
      " 0.99930994 0.99941052]\n",
      "[0.99930744 0.99924775 0.98557496 0.99880101 0.99832349 0.99822153\n",
      " 0.99677631 0.99887008]\n",
      "[0.99989973 0.99995443 0.99885616 0.99983442 0.99970889 0.99965002\n",
      " 0.99773585 0.99600691]\n",
      "[0.97702658 0.97988838 0.98592694 0.99146878 0.98386309 0.97855189\n",
      " 0.9862647  0.94768485]\n"
     ]
    }
   ],
   "source": [
    "# ALL BEHAV\n",
    "\n",
    "# number of bootstraps\n",
    "numBoots = gamal_PrepProj.shape[2]\n",
    "\n",
    "# initialize vector to hold R2\n",
    "allR2_pca = np.zeros((numBoots,R_est))\n",
    "allR2_mgamal = np.zeros((numBoots,R_est))\n",
    "allR2_sca = np.zeros((numBoots,R_est))\n",
    "allR2_dpca = np.zeros((numBoots,R_est))\n",
    "\n",
    "# cycle through bootstrap repetitions\n",
    "for n in range(numBoots):\n",
    "    gProj = np.concatenate((gamal_PrepProj[:,:,n],gamal_MoveProj[:,:,n],gamal_PostProj[:,:,n]),axis = -1)\n",
    "    gProj = gProj.reshape(gProj.shape[0],-1)\n",
    "\n",
    "    # pull out PCA bootstrap latents\n",
    "    Y = pca_latents[:,:,n]\n",
    "    # pull out all gamal projections\n",
    "    X = gProj\n",
    "    # regress\n",
    "    B = np.linalg.inv(X.T@X) @ X.T @ Y\n",
    "    # reconstruct Y \n",
    "    Y_hat = X @ B\n",
    "    # calculate R2\n",
    "    ss_tot = np.sum((Y - np.mean(Y,axis = 0))**2, axis = 0)\n",
    "    ss_res = np.sum((Y - Y_hat)**2,axis = 0)\n",
    "    allR2_pca[n,:] = 1 - (ss_res/ss_tot)\n",
    "\n",
    "    # pull out dPCA bootstrap latents\n",
    "    Y = dpca_latents[:,:,n]\n",
    "    # pull out all gamal projections\n",
    "    X = gProj\n",
    "    # regress\n",
    "    B = np.linalg.inv(X.T@X) @ X.T @ Y\n",
    "    # reconstruct Y \n",
    "    Y_hat = X @ B\n",
    "    # calculate R2\n",
    "    ss_tot = np.sum((Y - np.mean(Y,axis = 0))**2, axis = 0)\n",
    "    ss_res = np.sum((Y - Y_hat)**2,axis = 0)\n",
    "    allR2_dpca[n,:] = 1 - (ss_res/ss_tot)\n",
    "\n",
    "    # pull out mixed gamal bootstrap latents\n",
    "    Y = mix_gamal_latents[:,:,n]\n",
    "    # pull out all gamal projections\n",
    "    X = gProj\n",
    "    # regress\n",
    "    B = np.linalg.inv(X.T@X) @ X.T @ Y\n",
    "    # reconstruct Y \n",
    "    Y_hat = X @ B\n",
    "    # calculate R2\n",
    "    ss_tot = np.sum((Y - np.mean(Y,axis = 0))**2, axis = 0)\n",
    "    ss_res = np.sum((Y - Y_hat)**2,axis = 0)\n",
    "    allR2_mgamal[n,:] = 1 - (ss_res/ss_tot)\n",
    "\n",
    "    # pull out SCA bootstrap latents\n",
    "    Y = sca_latents[:,:,n]\n",
    "    # pull out all gamal projections\n",
    "    X = gProj\n",
    "    # regress\n",
    "    B = np.linalg.inv(X.T@X) @ X.T @ Y\n",
    "    # reconstruct Y \n",
    "    Y_hat = X @ B\n",
    "    # calculate R2\n",
    "    ss_tot = np.sum((Y - np.mean(Y,axis = 0))**2, axis = 0)\n",
    "    ss_res = np.sum((Y - Y_hat)**2,axis = 0)\n",
    "    allR2_sca[n,:] = 1 - (ss_res/ss_tot)\n",
    "\n",
    "#print first bootstrap's max R2's\n",
    "print(allR2_mgamal[0])\n",
    "print(allR2_sca[0])\n",
    "print(allR2_pca[0])\n",
    "print(allR2_dpca[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# np.random.seed(42)\n",
    "# T, R = 1000, 3\n",
    "\n",
    "# # 1 Create synthetic PCA latents (uncorrelated, anisotropic)\n",
    "# Y = np.random.randn(T, R) @ np.diag([3, 1, 0.3])\n",
    "# print(\"Correlation of original Y:\\n\", np.round(np.corrcoef(Y.T), 3))\n",
    "\n",
    "# # 2 Apply a random orthogonal rotation\n",
    "# Q, _ = np.linalg.qr(np.random.randn(R, R))\n",
    "# Y_null = Y @ Q\n",
    "# print(\"\\nCorrelation of rotated Y_null:\\n\", np.round(np.corrcoef(Y_null.T), 3))\n",
    "\n",
    "# # 3 Orthogonalize Y_null again using SVD (equivalent to PCA)\n",
    "# U, S, Vt = np.linalg.svd(Y_null, full_matrices=False)\n",
    "# Y_reorth = U @ np.diag(S)\n",
    "# print(\"\\nCorrelation of re-orthogonalized Y_reorth:\\n\", np.round(np.corrcoef(Y_reorth.T), 3))\n",
    "\n",
    "# # Compare subspace alignment (Y vs reorthogonalized)\n",
    "# corr_subspace = np.abs(np.corrcoef(Y.T, Y_reorth.T)[:R, R:])\n",
    "# print(\"\\nSubspace correlation between Y and Y_reorth (abs):\\n\", np.round(corr_subspace, 3))\n",
    "\n",
    "# # -------------------------------------------\n",
    "# # 4 Visualize 2D projection\n",
    "# # -------------------------------------------\n",
    "# fig, ax = plt.subplots(1, 3, figsize=(12,4))\n",
    "\n",
    "# ax[0].scatter(Y[:,0], Y[:,1], alpha=0.4)\n",
    "# ax[0].set_title(\"Original Y (PCA latents)\")\n",
    "# ax[0].axis('equal')\n",
    "\n",
    "# ax[1].scatter(Y_null[:,0], Y_null[:,1], alpha=0.4, color='orange')\n",
    "# ax[1].set_title(\"Rotated Y_null (correlated)\")\n",
    "# ax[1].axis('equal')\n",
    "\n",
    "# ax[2].scatter(Y_reorth[:,0], Y_reorth[:,1], alpha=0.4, color='green')\n",
    "# ax[2].set_title(\"Re-orthogonalized Y_reorth\\n(back to PCA orientation)\")\n",
    "# ax[2].axis('equal')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # -------------------------------------------\n",
    "# # 5 Optional: 3D comparison\n",
    "# # -------------------------------------------\n",
    "# fig = plt.figure(figsize=(10,4))\n",
    "# ax1 = fig.add_subplot(121, projection='3d')\n",
    "# ax1.scatter(Y[:,0], Y[:,1], Y[:,2], alpha=0.3)\n",
    "# ax1.set_title(\"Original PCA latents\")\n",
    "\n",
    "# ax2 = fig.add_subplot(122, projection='3d')\n",
    "# ax2.scatter(Y_reorth[:,0], Y_reorth[:,1], Y_reorth[:,2], alpha=0.3, color='green')\n",
    "# ax2.set_title(\"Re-orthogonalized Y_reorth (same subspace)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "Y = np.random.randn(1000, 3) @ np.diag([3, 1, 0.3])\n",
    "Q, _ = np.linalg.qr(np.random.randn(3,3))\n",
    "Y_null = Y @ Q\n",
    "\n",
    "# Re-orthogonalize Y_null (PCA again)\n",
    "U, S, _ = np.linalg.svd(Y_null, full_matrices=False)\n",
    "Y_orth = U @ np.diag(S)\n",
    "\n",
    "# Compare subspaces\n",
    "print(np.allclose(np.abs(np.corrcoef(Y.T, Y_orth.T)[:3,3:]), np.eye(3), atol=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraction of colormap to use\n",
    "colorIdx = np.arange(0.55,1,0.4/8)\n",
    "\n",
    "# define ssa colors\n",
    "sca_cMap = sns.cubehelix_palette(start = 0.1,rot = 0.6,dark = 0.15, light = 0.8,as_cmap = True,gamma = 1.1)\n",
    "sca_cMap = sca_cMap(colorIdx)\n",
    "\n",
    "# define pca colors\n",
    "pca_cMap = sns.cubehelix_palette(start = 0.1,rot = 0.6,dark = 0.15, light = 0.8,as_cmap = True,gamma = 0.7,hue = 0.3)\n",
    "pca_cMap = pca_cMap(colorIdx)\n",
    "\n",
    "mgamal_cMap = ['#e8a048', '#d48b3f', '#c07737', '#ac632e', '#984e26', '#843a1d', '#702615', '#5c120d']\n",
    "\n",
    "dpca_cMap  = ['#0bffe0', '#0ae2c7', '#0ac6af', '#0aaa97', '#0a8d7e', '#0a7166', '#0a554e', '#0a3936']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Adjust axis label colors for better PDF visibility\n",
    "plt.rcParams['text.color'] = 'k'\n",
    "plt.rcParams['xtick.color'] = 'k'\n",
    "plt.rcParams['ytick.color'] = 'k'\n",
    "plt.rcParams['axes.labelcolor'] = 'k'\n",
    "\n",
    "# General style adjustments\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['axes.spines.left'] = True\n",
    "plt.rcParams['axes.spines.bottom'] = True\n",
    "\n",
    "# Define cap size and style\n",
    "capsize = 5\n",
    "capstyle = {'linestyle': ':'}\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "# Add horizontal lines for \"all_xxx_recon\" mean  error bars\n",
    "all_scaR2_recon = np.reshape(allR2_sca, [-1, 1], order='F')\n",
    "mean_all_sca = np.mean(all_scaR2_recon)\n",
    "std_all_sca = np.std(all_scaR2_recon)\n",
    "ax.hlines(mean_all_sca, 0.8, 1.2, color=sca_cMap[0],  lw=2)\n",
    "ax.hlines([mean_all_sca - std_all_sca, mean_all_sca + std_all_sca], 0.8, 1.2, \n",
    "          color=sca_cMap[0], linestyle='--', lw=1)\n",
    "\n",
    "all_pcaR2_recon = np.reshape(allR2_pca, [-1, 1], order='F')\n",
    "mean_all_pca = np.mean(all_pcaR2_recon)\n",
    "std_all_pca = np.std(all_pcaR2_recon)\n",
    "ax.hlines(mean_all_pca, 1.8, 2.2, color=pca_cMap[0], lw=2)\n",
    "ax.hlines([mean_all_pca - std_all_pca, mean_all_pca + std_all_pca], 1.8, 2.2, \n",
    "          color=pca_cMap[0], linestyle='--', lw=1)\n",
    "\n",
    "all_mgamalR2_recon = np.reshape(allR2_mgamal, [-1, 1], order='F')\n",
    "mean_all_mgamal = np.mean(all_mgamalR2_recon)\n",
    "std_all_mgamal = np.std(all_mgamalR2_recon)\n",
    "ax.hlines(mean_all_mgamal, 2.8, 3.2, color=mgamal_cMap[-1],  lw=2)\n",
    "ax.hlines([mean_all_mgamal - std_all_mgamal, mean_all_mgamal + std_all_mgamal], 2.8, 3.2, \n",
    "          color=mgamal_cMap[-1], linestyle='--', lw=1)\n",
    "\n",
    "all_dpcaR2_recon = np.reshape(allR2_dpca, [-1, 1], order='F')\n",
    "mean_all_dpca = np.mean(all_dpcaR2_recon)\n",
    "std_all_dpca = np.std(all_dpcaR2_recon)\n",
    "ax.hlines(mean_all_dpca, 3.8, 4.2, color=dpca_cMap[-1], lw=2)\n",
    "ax.hlines([mean_all_dpca - std_all_dpca, mean_all_dpca + std_all_dpca], 3.8, 4.2, \n",
    "          color=dpca_cMap[-1], linestyle='--', lw=1)\n",
    "\n",
    "# Plot SCA reconstructions\n",
    "scaR2_recon = np.reshape(maxR2_sca, [-1, 1], order='F')\n",
    "ax.errorbar(1, np.mean(scaR2_recon), np.std(scaR2_recon), color=sca_cMap[0], lw=3, capsize=capsize)\n",
    "ax.plot(1, np.mean(scaR2_recon), 'o', color=sca_cMap[0], ms=8)\n",
    "\n",
    "# Plot PCA reconstructions\n",
    "pcaR2_recon = np.reshape(maxR2_pca, [-1, 1], order='F')\n",
    "ax.errorbar(2, np.mean(pcaR2_recon), np.std(pcaR2_recon), color=pca_cMap[0], lw=3, capsize=capsize)\n",
    "ax.plot(2, np.mean(pcaR2_recon), 'o', color=pca_cMap[0], ms=8)\n",
    "\n",
    "# Plot Mixed Gamal reconstructions\n",
    "mgamalR2_recon = np.reshape(maxR2_mgamal, [-1, 1], order='F')\n",
    "ax.errorbar(3, np.mean(mgamalR2_recon), np.std(mgamalR2_recon), color=mgamal_cMap[-1], lw=3, capsize=capsize)\n",
    "ax.plot(3, np.mean(mgamalR2_recon), 'o', color=mgamal_cMap[-1], ms=8)\n",
    "\n",
    "\n",
    "# Plot dPCA reconstructions\n",
    "dpcaR2_recon = np.reshape(maxR2_dpca, [-1, 1], order='F')\n",
    "ax.errorbar(4, np.mean(dpcaR2_recon), np.std(dpcaR2_recon), color=dpca_cMap[-1], lw=3, capsize=capsize)\n",
    "ax.plot(4, np.mean(dpcaR2_recon), 'o', color=dpca_cMap[-1], ms=8)\n",
    "\n",
    "# Final plot adjustments\n",
    "ax.set_xlim(0.5, 4.5)\n",
    "ax.set_ylim(0.5, 1.02)\n",
    "ax.set_xticks([1, 2, 3, 4])\n",
    "ax.set_xticklabels(['SCA', 'PCA', 'Mixed Gamal','dPCA'],size=10)\n",
    "ax.set_yticks([0.5, 1.0])\n",
    "ax.set_ylabel('R2')\n",
    "\n",
    "# Remove border around figure\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Plot baseline: random rotations of PCA latents\n",
    "rotR2_recon = np.reshape(maxR2_pca_rotate, [-1, 1], order='F')\n",
    "mean_rot = np.mean(rotR2_recon)\n",
    "std_rot  = np.std(rotR2_recon)\n",
    "ax.hlines(mean_rot, 0.6, 4.4, color='gray', lw=2, linestyle='-')\n",
    "# ax.hlines([mean_rot - std_rot, mean_rot + std_rot], 0.6, 4.4,\n",
    "#           color='gray', linestyle='--', lw=1)\n",
    "\n",
    "# # # save directory\n",
    "figDir = '/Users/sherryan/sca/sca_analysis/'\n",
    "\n",
    "# # save\n",
    "plt.savefig(figDir + monkName + '_r2_dist.pdf', dpi = 'figure')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7238000615831802"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference in recon R2 using single behavior (maxR2)\n",
    "r2meanDiff = [np.mean(maxR2_sca[i,:])-np.mean(maxR2_pca[i,:]) for i in range(100)]\n",
    "prop = sum(1 for i in r2meanDiff if i > 0)/len(r2meanDiff)\n",
    "print('SCA vs PCA',prop)\n",
    "\n",
    "r2meanDiff = [np.mean(maxR2_sca[i,:])-np.mean(maxR2_mgamal[i,:]) for i in range(100)]\n",
    "prop = sum(1 for i in r2meanDiff if i > 0)/len(r2meanDiff)\n",
    "print('SCA vs mixed Gamal',prop)\n",
    "\n",
    "r2meanDiff = [np.mean(maxR2_sca[i,:])-np.mean(maxR2_dpca[i,:]) for i in range(100)]\n",
    "prop = sum(1 for i in r2meanDiff if i > 0)/len(r2meanDiff)\n",
    "print('SCA vs dPCA',prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference in recon R2, between using all vs. single behavior (allR2 - maxR2)\n",
    "r2meanDiff = [np.mean(allR2_sca[i,:]-maxR2_sca[i,:])-np.mean(allR2_pca[i,:]-maxR2_pca[i,:]) for i in range(100)]\n",
    "prop = 1-sum(1 for i in r2meanDiff if i > 0)/len(r2meanDiff)\n",
    "print('SCA vs PCA',prop)\n",
    "\n",
    "r2meanDiff = [np.mean(allR2_sca[i,:]-maxR2_sca[i,:])-np.mean(allR2_mgamal[i,:]-maxR2_mgamal[i,:]) for i in range(100)]\n",
    "prop = 1-sum(1 for i in r2meanDiff if i > 0)/len(r2meanDiff)\n",
    "print('SCA vs mixed Gamal',prop)\n",
    "\n",
    "r2meanDiff = [np.mean(allR2_sca[i,:]-maxR2_sca[i,:])-np.mean(allR2_dpca[i,:]-maxR2_dpca[i,:]) for i in range(100)]\n",
    "prop = 1-sum(1 for i in r2meanDiff if i > 0)/len(r2meanDiff)\n",
    "print('SCA vs dPCA',prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdt_env",
   "language": "python",
   "name": "sdt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
