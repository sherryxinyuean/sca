{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.linalg import orth\n",
    "import time\n",
    "\n",
    "from sca.models import SCA, WeightedPCA\n",
    "from sca.util import get_sample_weights, get_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate data\n",
    "Data is simulated from sparsely occurring latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Parameters\n",
    "n_pad = 200  # Padding before and after\n",
    "conditions = [\n",
    "    (100, 200, 400, 1.0 + 0.02, 1.0),      # Condition 1\n",
    "    (100, 100, 400, 1.0 + 0.02, 1.0),      # Condition 2\n",
    "    (200, 200, 400, -1.0 - 0.02, -1.0),    # Condition 3\n",
    "]\n",
    "\n",
    "# Helper function to generate each condition block\n",
    "def create_condition(f1_dur, cooccur_dur, f2_dur, f1_val, f2_val):\n",
    "    f1_only = np.column_stack([np.full(f1_dur, f1_val), np.zeros(f1_dur)])\n",
    "    cooccur = np.column_stack([np.full(cooccur_dur, f1_val), np.full(cooccur_dur, f2_val)])\n",
    "    f2_only = np.column_stack([np.zeros(f2_dur), np.full(f2_dur, f2_val)])\n",
    "    return np.vstack([f1_only, cooccur, f2_only])\n",
    "\n",
    "# Build all condition segments with padding\n",
    "all_segments = []\n",
    "for (f1_dur, cooccur_dur, f2_dur, f1_val, f2_val) in conditions:\n",
    "    cond = create_condition(f1_dur, cooccur_dur, f2_dur, f1_val, f2_val)\n",
    "    pad_before = np.zeros((n_pad, 2))\n",
    "    pad_after = np.zeros(((1000-f1_dur-cooccur_dur-f2_dur), 2))\n",
    "    segment = np.vstack([pad_before, cond, pad_after])\n",
    "    all_segments.append(segment)\n",
    "\n",
    "# Plot conditions in separate subplots (stacked vertically)\n",
    "fig, axes = plt.subplots(len(all_segments), 1, figsize=(10, 6), sharex=False)\n",
    "\n",
    "for i, segment in enumerate(all_segments):\n",
    "    time = np.arange(segment.shape[0])\n",
    "    axes[i].plot(time, segment[:, 0], label=\"Factor 1\",)\n",
    "    axes[i].plot(time, segment[:, 1], label=\"Factor 2\")\n",
    "\n",
    "\n",
    "axes[-1].set_xlabel(\"Time\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('sim1_ground_truth.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_samples = 1000              # Samples per condition\n",
    "n_pad = 400                   # Padding before and after\n",
    "\n",
    "# Define condition blocks\n",
    "cond1 = np.column_stack([np.ones(n_samples)*1.5+0.02, np.zeros(n_samples)])     # [1, 0]\n",
    "cond2 = np.column_stack([np.zeros(n_samples), np.ones(n_samples)*2])            # [0, 1]\n",
    "cond3 = np.column_stack([np.ones(n_samples)+0.02, np.ones(n_samples)])          # [1, 1]\n",
    "\n",
    "conditions = [cond1, cond2, cond3]\n",
    "\n",
    "# Build each condition segment with padding\n",
    "all_segments = []\n",
    "for cond in conditions:\n",
    "    pad_before = np.zeros((n_pad, 2))\n",
    "    pad_after = np.zeros((n_pad, 2))\n",
    "    segment = np.vstack([pad_before, cond, pad_after])\n",
    "    all_segments.append(segment)\n",
    "\n",
    "# Plot conditions in separate subplots (stacked vertically)\n",
    "fig, axes = plt.subplots(len(all_segments), 1, figsize=(10, 6), sharex=False)\n",
    "\n",
    "for i, segment in enumerate(all_segments):\n",
    "    time = np.arange(segment.shape[0])\n",
    "    axes[i].set_ylim(-0.1, 2.1)\n",
    "    axes[i].plot(time, segment[:, 0], label=\"Factor 1\")\n",
    "    axes[i].plot(time, segment[:, 1], label=\"Factor 2\")\n",
    "\n",
    "axes[-1].set_xlabel(\"Time\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('sim2_ground_truth.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Parameters\n",
    "# factor1_duration = 1000\n",
    "# factor2_duration = 500\n",
    "# n_pad = 400  # Padding before and after\n",
    "\n",
    "# # Define condition blocks\n",
    "# # Single factor conditions\n",
    "# i = 3\n",
    "# cond1 = np.column_stack([np.ones(factor1_duration)+0.02, np.zeros(factor1_duration)])  # Factor 1 active\n",
    "# cond2 = np.column_stack([np.zeros(i*factor2_duration), np.ones(i*factor2_duration)])       # Factor 2 active\n",
    "\n",
    "# # Dual factor condition (pad factor 2 to match factor 1's length)\n",
    "# factor1 = np.ones(factor1_duration) + 0.02\n",
    "# factor2 = np.concatenate([np.ones(factor2_duration), np.zeros(factor1_duration - factor2_duration)])\n",
    "# cond3 = np.column_stack([factor1, factor2])\n",
    "\n",
    "# cond4 = np.column_stack([-np.ones(factor1_duration)+0.02, np.zeros(factor1_duration)])  # Factor 1 active\n",
    "# cond5 = np.column_stack([np.zeros(i*factor2_duration), -np.ones(i*factor2_duration)])       # Factor 2 active\n",
    "\n",
    "# # factor1 = -np.ones(factor1_duration) + 0.02\n",
    "# # factor2 = np.concatenate([-np.ones(factor2_duration), np.zeros(factor1_duration - factor2_duration)])\n",
    "# # cond6 = np.column_stack([factor1, factor2])\n",
    "\n",
    "# # Combine with padding\n",
    "# all_segments = []\n",
    "# segment_starts = []\n",
    "\n",
    "# current_index = 0\n",
    "# # for cond in [cond1, cond2, cond3]:\n",
    "# for cond in [cond1, cond2, cond3, cond4, cond5]:\n",
    "#     pad_before = np.zeros((n_pad, 2))\n",
    "#     pad_after = np.zeros((n_pad, 2))\n",
    "#     segment = np.vstack([pad_before, cond, pad_after])\n",
    "#     all_segments.append(segment)\n",
    "#     segment_starts.append(current_index)\n",
    "#     current_index += segment.shape[0]\n",
    "\n",
    "# # Final data array\n",
    "# Z = np.vstack(all_segments)\n",
    "# time = np.arange(Z.shape[0])\n",
    "\n",
    "# # Plot\n",
    "# plt.figure(figsize=(12, 5))\n",
    "# plt.plot(time, Z[:, 0], label=\"Factor 1\", color='blue')\n",
    "# plt.plot(time, Z[:, 1], label=\"Factor 2\", color='green')\n",
    "\n",
    "# # Draw vertical lines at segment starts (except the first one)\n",
    "# for idx in segment_starts[1:]:\n",
    "#     plt.axvline(idx, color='gray', linestyle='--')\n",
    "\n",
    "# # Final styling\n",
    "# plt.axhline(0, color='black', linewidth=0.5)\n",
    "# plt.xlabel(\"Time\")\n",
    "# plt.ylabel(\"Factor\")\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.vstack(all_segments)\n",
    "np.random.seed(0) #To get the same simulated data\n",
    "\n",
    "N_neurons=50 #Number of neurons\n",
    "R_sim=2 #Number of dimensions in lowD representations\n",
    "\n",
    "#Orthogonal matrix that projects low dimensional space to full neural space\n",
    "V_tmp=orth(npr.randn(R_sim,N_neurons).T).T \n",
    "\n",
    "#Create high-dimensional neural activity    \n",
    "b=npr.randn(N_neurons) #Offset of neurons\n",
    "X0=Z@V_tmp[:R_sim,:]+b #Project into high-dimensional space and add offset\n",
    "noise_level = 0.1\n",
    "X0=X0+noise_level*npr.randn(X0.shape[0],X0.shape[1]) #Add noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example neurons to plot\n",
    "example_neurons = [0, 5]   # pick any two neuron indices\n",
    "n_conditions = 3\n",
    "\n",
    "# Split time into conditions\n",
    "n_time_total, n_neurons = X0.shape\n",
    "T = n_time_total // n_conditions   # samples per condition\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "for row, f_idx in enumerate(example_neurons):       # rows = factors\n",
    "    for col in range(n_conditions):                 # cols = conditions\n",
    "        start = col * T\n",
    "        end = (col + 1) * T\n",
    "        trace = X0[start:end, f_idx]\n",
    "\n",
    "        ax = plt.subplot(len(example_neurons), n_conditions, row*n_conditions + col + 1)\n",
    "        ax.plot(trace,color  = \"#6e0f3e\")\n",
    "        ax.set_yticks([])\n",
    "\n",
    "        # Labels\n",
    "        if row == len(example_neurons) - 1:   # bottom row x-labels\n",
    "            ax.set_xlabel(\"Time\")\n",
    "        else:\n",
    "            ax.set_xticks([])\n",
    "        if col == 0:                          # left col y-labels\n",
    "            ax.set_ylabel(f\"Factor {f_idx+1}\")\n",
    "        if row == 0:                          # top row titles\n",
    "            ax.set_title(f\"Cond {col+1}\")\n",
    "\n",
    "plt.savefig('sim1_single_neurons.pdf')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "for i in range(R_sim):\n",
    "    \n",
    "    #Plot ground truth\n",
    "    plt.subplot(R_sim,2,2*i+1)\n",
    "    plt.plot((Z)[:,i]) \n",
    "    \n",
    "    plt.ylim([-1.1, 1.1])\n",
    "    plt.yticks([])\n",
    "    if i<R_sim-1:\n",
    "        plt.xticks([])\n",
    "    else:\n",
    "        plt.xlabel('Time')\n",
    "    \n",
    "    # Plot Example neurons\n",
    "    plt.subplot(R_sim,2,2*i+2)\n",
    "    plt.plot((X0)[:,i]) \n",
    "    \n",
    "#     plt.ylim([-1.1, 1.1])\n",
    "    plt.yticks([])    \n",
    "    if i<R_sim-1:\n",
    "        plt.xticks([])\n",
    "    else:\n",
    "        plt.xlabel('Time')\n",
    "\n",
    "# Titles\n",
    "plt.subplot(R_sim,2,1)\n",
    "plt.title('Simulated latents')\n",
    "\n",
    "plt.subplot(R_sim,2,2)\n",
    "plt.title('Example simulated \"neurons\" ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have found that the method usually works better when zero-centering the data.\n",
    "\n",
    "In this specific example, if you don't zero-center the data, it will take ~10000 iterations to converge to the ground truth, rather than ~2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.copy(X0)\n",
    "X=np.copy(X0-np.mean(X0,axis=0)[None,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set required model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of dimensions in the low-D model you're fitting\n",
    "n_components=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set some optional model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these have default values, so it's not essential to set them. Below just shows most of the parameters you can set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of epochs of model fitting (default is 3000)\n",
    "n_epochs=3000\n",
    "\n",
    "#Learning rate of model fitting (default is .001)\n",
    "lr=.001\n",
    "\n",
    "#Whether to have a strict orthogonality constraint in the loadings (default is False)\n",
    "#Note that the version of SCA that has orth=False runs faster\n",
    "# orth=False\n",
    "\n",
    "#Initialization of weights - can be 'pca' or 'rand' (default is 'pca')\n",
    "init='pca'\n",
    "\n",
    "#We would recommend using the default lambda hyperparameters, at least to start. \n",
    "#When running SCA, it will print what the default values are for the given dataset\n",
    "\n",
    "#Strength of the sparsity penalty\n",
    "lam_sparse=.1\n",
    "\n",
    "#Strength of the orthogonality penality (Note - This is only used in the version without a hard orthogonality constraint)\n",
    "lam_orthog=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How much to weight each data point in time\n",
    "#(this can be helpful for making sure dimensions still aim to explain time points with low activity)\n",
    "\n",
    "sample_weights=np.ones([X.shape[0],1]) #Weight equally\n",
    "\n",
    "# sample_weights=get_sample_weights(X) #Weight inversely to norm of activity at each time point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Weighted PCA Model (for comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit weighted PCA\n",
    "#Note that this function does not automatically subtract the mean from the data (as in many PCA functions)\n",
    "\n",
    "#Decleare model\n",
    "wpca=WeightedPCA(n_components=n_components,rotate=False)\n",
    "wpca_vari=WeightedPCA(n_components=n_components,rotate=True)\n",
    "\n",
    "#Fit and get the low dimensional representation (the principal components)\n",
    "#Note that the sample_weight input is optional and will default to no sample weighting\n",
    "pca_latent = wpca.fit_transform(X,sample_weight=sample_weights)\n",
    "pca_vari_latent = wpca_vari.fit_transform(X,sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_weighted = X * sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "ica = FastICA(n_components=n_components)\n",
    "ica_latent = ica.fit_transform(X)     # Independent components\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit SCA Model\n",
    "We show options for running SCA below (with and without optional parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Declare SCA model without all the optional parameters\n",
    "# sca=SCA(n_components=n_components,n_epochs=6000,lam_sparse = .1, init='rand')\n",
    "sca=SCA(n_components=n_components)\n",
    "\n",
    "#Declare SCA model with the optional parameters\n",
    "# sca=SCA(n_components=n_components,orth=orth, lam_sparse=lam_sparse, lam_orthog=lam_orthog, lr=lr,n_epochs=n_epochs, init=init)\n",
    "\n",
    " \n",
    "#Fit the model and get the low dimensional representation\n",
    "#Note that the sample_weight input is optional and will default to no sample weighting\n",
    "sca_latent=sca.fit_transform(X=X, sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the loss over all iterations\n",
    "plt.figure()\n",
    "plt.plot(sca.losses)\n",
    "plt.xlabel('Training Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over training')\n",
    "\n",
    "#Plot the loss over the last 100 iterations (to see if it has truly hit a plateau)\n",
    "# plt.figure()\n",
    "# plt.plot(losses[-100:-1])\n",
    "# plt.xlabel('Training Epoch')\n",
    "# plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Latents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot unordered lowD representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ground truth\n",
    "# T = 3300\n",
    "# Z_extra=np.zeros([T,n_components])\n",
    "# Z_extra[:,:R_sim]=Z\n",
    "\n",
    "Z_extra=Z\n",
    "\n",
    "plt.figure(figsize=(20, 5))  # Wider figure for 4 columns\n",
    "\n",
    "for i in range(n_components):\n",
    "    \n",
    "    # --- Plot Ground Truth ---\n",
    "    plt.subplot(n_components, 5, 5 * i + 1)\n",
    "    plt.plot(Z_extra[:, i])\n",
    "    # plt.ylim([-1.6, 1.6])\n",
    "    if i < n_components - 1:\n",
    "        plt.xticks([])\n",
    "    else:\n",
    "        plt.xlabel('Time')\n",
    "    \n",
    "    # --- Plot SCA ---\n",
    "    plt.subplot(n_components, 5, 5 * i + 2)\n",
    "    plt.plot(sca_latent[:, i])\n",
    "    # plt.ylim([-1.6, 1.6])\n",
    "    if i < n_components - 1:\n",
    "        plt.xticks([])\n",
    "    else:\n",
    "        plt.xlabel('Time')\n",
    "\n",
    "    # --- Plot PCA ---\n",
    "    plt.subplot(n_components, 5, 5 * i + 3)\n",
    "    plt.plot(pca_latent[:, i])\n",
    "    # plt.ylim([-1.6, 1.6])\n",
    "    if i < n_components - 1:\n",
    "        plt.xticks([])\n",
    "    else:\n",
    "        plt.xlabel('Time')\n",
    "\n",
    "    # --- Plot PCA+Varimax ---\n",
    "    plt.subplot(n_components, 5, 5 * i + 4)\n",
    "    plt.plot(pca_vari_latent[:, i])\n",
    "    # plt.ylim([-1.6, 1.6])\n",
    "    if i < n_components - 1:\n",
    "        plt.xticks([])\n",
    "    else:\n",
    "        plt.xlabel('Time')    \n",
    "\n",
    "    # --- Plot ICA ---\n",
    "    plt.subplot(n_components, 5, 5 * i + 5)\n",
    "    plt.plot(ica_latent[:, i])\n",
    "    # plt.ylim([-1.6, 1.6])\n",
    "    if i < n_components - 1:\n",
    "        plt.xticks([])\n",
    "    else:\n",
    "        plt.xlabel('Time')\n",
    "\n",
    "# Titles\n",
    "plt.subplot(n_components, 5, 1)\n",
    "plt.title('True LowD Projections')\n",
    "\n",
    "plt.subplot(n_components, 5, 2)\n",
    "plt.title('SCA LowD Projections')\n",
    "\n",
    "plt.subplot(n_components, 5, 3)\n",
    "plt.title('PCA LowD Projections')\n",
    "\n",
    "plt.subplot(n_components, 5, 4)\n",
    "plt.title('PCA+Varimax LowD Projections')\n",
    "\n",
    "plt.subplot(n_components, 5, 5)\n",
    "plt.title('ICA LowD Projections')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "corr = np.corrcoef(sca_latent.T, Z.T)[:2, 2:]  # shape (2,2)\n",
    "\n",
    "# Step 2: find best matching order\n",
    "order = np.argmax(np.abs(corr), axis=0)   # which PCA latent matches each factor\n",
    "signs = np.sign(corr[order, range(2)])    # sign of that correlation\n",
    "\n",
    "# Step 3: reorder and flip PCA latents\n",
    "sca_aligned = np.zeros_like(sca_latent)\n",
    "for j in range(2):  # for each factor\n",
    "    sca_aligned[:, j] = sca_latent[:, order[j]] * signs[j]\n",
    "\n",
    "# Example neurons to plot\n",
    "example_factors = [0, 1]   # pick any two neuron indices\n",
    "n_conditions = 3\n",
    "\n",
    "# Split time into conditions\n",
    "n_time_total, n_neurons = sca_latent.shape\n",
    "T = n_time_total // n_conditions   # samples per condition\n",
    "\n",
    "# plt.figure(figsize=(9, 6))\n",
    "fig, axes = plt.subplots(\n",
    "    n_neurons, n_conditions,\n",
    "    figsize=(9, 6),\n",
    "    # sharex=True, sharey=True   # makes all panels share axes\n",
    ")\n",
    "\n",
    "for row, f_idx in enumerate(example_factors):       # rows = factors\n",
    "    for col in range(n_conditions):                 # cols = conditions\n",
    "        start = col * T\n",
    "        end = (col + 1) * T\n",
    "        trace = sca_aligned[start:end, f_idx]\n",
    "        \n",
    "        ax = axes[row, col]\n",
    "\n",
    "        ax = plt.subplot(len(example_factors), n_conditions, row*n_conditions + col + 1)\n",
    "        ax.plot(trace,color  = \"#6e0f3e\")\n",
    "        ax.set_yticks([])\n",
    "\n",
    "        # Labels\n",
    "        if row == len(example_factors) - 1:   # bottom row x-labels\n",
    "            ax.set_xlabel(\"Time\")\n",
    "        else:\n",
    "            ax.set_xticks([])\n",
    "        if col == 0:                          # left col y-labels\n",
    "            ax.set_ylabel(f\"Factor {f_idx+1}\")\n",
    "        if row == 0:                          # top row titles\n",
    "            ax.set_title(f\"Cond {col+1}\")\n",
    "plt.savefig('sim1_SCA_factors.pdf')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "corr = np.corrcoef(pca_latent.T, Z.T)[:2, 2:]  # shape (2,2)\n",
    "\n",
    "# Step 2: find best matching order\n",
    "order = np.argmax(np.abs(corr), axis=0)   # which PCA latent matches each factor\n",
    "signs = np.sign(corr[order, range(2)])    # sign of that correlation\n",
    "\n",
    "# Step 3: reorder and flip PCA latents\n",
    "pca_aligned = np.zeros_like(pca_latent)\n",
    "for j in range(2):  # for each factor\n",
    "    pca_aligned[:, j] = pca_latent[:, order[j]] * signs[j]\n",
    "\n",
    "# Example neurons to plot\n",
    "example_factors = [0, 1]   # pick any two neuron indices\n",
    "n_conditions = 3\n",
    "\n",
    "# Split time into conditions\n",
    "n_time_total, n_neurons = pca_latent.shape\n",
    "T = n_time_total // n_conditions   # samples per condition\n",
    "\n",
    "# plt.figure(figsize=(9, 6))\n",
    "fig, axes = plt.subplots(\n",
    "    n_neurons, n_conditions,\n",
    "    figsize=(9, 6),\n",
    "    # sharex=True, sharey=True   # makes all panels share axes\n",
    ")\n",
    "\n",
    "for row, f_idx in enumerate(example_factors):       # rows = factors\n",
    "    for col in range(n_conditions):                 # cols = conditions\n",
    "        start = col * T\n",
    "        end = (col + 1) * T\n",
    "        trace = pca_aligned[start:end, f_idx]\n",
    "\n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        ax = plt.subplot(len(example_factors), n_conditions, row*n_conditions + col + 1)\n",
    "        ax.plot(trace,color  = \"#6e0f3e\")\n",
    "        ax.set_yticks([])\n",
    "\n",
    "        # Labels\n",
    "        if row == len(example_factors) - 1:   # bottom row x-labels\n",
    "            ax.set_xlabel(\"Time\")\n",
    "        else:\n",
    "            ax.set_xticks([])\n",
    "        if col == 0:                          # left col y-labels\n",
    "            ax.set_ylabel(f\"Factor {f_idx+1}\")\n",
    "        if row == 0:                          # top row titles\n",
    "            ax.set_title(f\"Cond {col+1}\")\n",
    "\n",
    "plt.savefig('sim1_PCA_factors.pdf')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order low-dimensional representations by time of maximum variance explained by that dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Amount of squared activity each dimension explains in PCA\n",
    "infs_pca=[np.sum((pca_latent[:,i:i+1]@wpca.params['V'][i:i+1,:])**2,axis=1) for i in range(n_components)]\n",
    "\n",
    "#Amount of squared activity each dimension explains in SCA\n",
    "infs_sca=[np.sum((sca_latent[:,i:i+1]@sca.params['V'][:,i:i+1].T)**2,axis=1) for i in range(n_components)]\n",
    "\n",
    "infs_ica = [\n",
    "    np.sum((ica_latent[:, i:i+1] @ ica.mixing_[:, i:i+1].T)**2, axis=1)\n",
    "    for i in range(n_components)\n",
    "]\n",
    "\n",
    "#Find the time point of each dimension that has the largest squared activity explained\n",
    "max_array_pca=[np.argmax(infs_pca[i]) for i in range(n_components)]\n",
    "max_array_sca=[np.argmax(infs_sca[i]) for i in range(n_components)]\n",
    "max_array_ica=[np.argmax(infs_ica[i]) for i in range(n_components)]\n",
    "\n",
    "\n",
    "#Order dimensions\n",
    "pca_order=np.argsort(np.array(max_array_pca))\n",
    "sca_order=np.argsort(np.array(max_array_sca))\n",
    "ica_order=np.argsort(np.array(max_array_ica))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ground truth\n",
    "Z_extra=np.zeros([T,n_components])\n",
    "Z_extra[:,:R_sim]=Z\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "for i in range(n_components):\n",
    "    \n",
    "    #Plot ground truth\n",
    "    plt.subplot(n_components,3,3*i+1)\n",
    "    plt.plot((Z_extra)[:,i]) \n",
    "    \n",
    "    plt.ylim([-1.6, 1.6])\n",
    "    # plt.yticks([])\n",
    "    if i<n_components-1:\n",
    "        plt.xticks([])\n",
    "    else:\n",
    "        plt.xlabel('Time')\n",
    "    \n",
    "    # Plot SCA results\n",
    "    plt.subplot(n_components,3,3*i+2)\n",
    "    plt.plot(sca_latent[:,sca_order[i]])\n",
    "    \n",
    "    plt.ylim([-1.6, 1.6])\n",
    "    # plt.yticks([])    \n",
    "    if i<n_components-1:\n",
    "        plt.xticks([])\n",
    "    else:\n",
    "        plt.xlabel('Time')\n",
    "\n",
    "    # Plot PCA results\n",
    "    plt.subplot(n_components,3,3*i+3)\n",
    "    plt.plot(pca_latent[:,pca_order[i]])\n",
    "    \n",
    "    plt.ylim([-1.6, 1.6])\n",
    "    # plt.yticks([])\n",
    "    if i<n_components-1:\n",
    "        plt.xticks([])\n",
    "    else:\n",
    "        plt.xlabel('Time')        \n",
    "\n",
    "#Titles\n",
    "plt.subplot(n_components,3,1)\n",
    "plt.title('True LowD Projections')\n",
    "\n",
    "plt.subplot(n_components,3,2)\n",
    "plt.title('SCA LowD Projections')\n",
    "\n",
    "plt.subplot(n_components,3,3)\n",
    "plt.title('PCA LowD Projections')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "for i in range(n_components):\n",
    "    \n",
    "    #Plot ground truth\n",
    "    plt.subplot(n_components,4,4*i+1)\n",
    "    plt.plot((Z_extra)[:,i]) \n",
    "    \n",
    "    plt.ylim([-1.6, 1.6])\n",
    "    # plt.yticks([])\n",
    "    if i<n_components-1:\n",
    "        plt.xticks([])\n",
    "    else:\n",
    "        plt.xlabel('Time')\n",
    "    \n",
    "    # Plot SCA results\n",
    "    plt.subplot(n_components,4,4*i+2)\n",
    "    plt.plot(sca_latent[:,sca_order[i]])\n",
    "    \n",
    "    plt.ylim([-1.6, 1.6])\n",
    "    # plt.yticks([])    \n",
    "    if i<n_components-1:\n",
    "        plt.xticks([])\n",
    "    else:\n",
    "        plt.xlabel('Time')\n",
    "\n",
    "    # Plot PCA results\n",
    "    plt.subplot(n_components,4,4*i+3)\n",
    "    plt.plot(pca_latent[:,pca_order[i]])\n",
    "    \n",
    "    plt.ylim([-1.6, 1.6])\n",
    "    # plt.yticks([])\n",
    "    if i<n_components-1:\n",
    "        plt.xticks([])\n",
    "    else:\n",
    "        plt.xlabel('Time')        \n",
    "\n",
    "    # Plot ICA results\n",
    "    plt.subplot(n_components,4,4*i+4)\n",
    "    plt.plot(ica_latent[:,ica_order[i]])\n",
    "    \n",
    "    # plt.ylim([-1.6, 1.6])\n",
    "    # plt.yticks([])\n",
    "    if i<n_components-1:\n",
    "        plt.xticks([])\n",
    "    else:\n",
    "        plt.xlabel('Time')   \n",
    "\n",
    "#Titles\n",
    "plt.subplot(n_components,4,1)\n",
    "plt.title('True LowD Projections')\n",
    "\n",
    "plt.subplot(n_components,4,2)\n",
    "plt.title('SCA LowD Projections')\n",
    "\n",
    "plt.subplot(n_components,4,3)\n",
    "plt.title('PCA LowD Projections')\n",
    "\n",
    "plt.subplot(n_components,4,4)\n",
    "plt.title('ICA LowD Projections')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at how orthogonal the projection is\n",
    "Show how orthogonal each of the latent dimensions are to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product=sca.params['V']@sca.params['V'].T\n",
    "plt.imshow(product,clim=[-1,1],cmap='RdBu')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and plot reconstructed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get reconstructed high-dimensionaldata\n",
    "Xhat=sca.reconstruct(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot example neurons\n",
    "\n",
    "plot_neurons=[0,1,2,3,4] #example neurons to plot\n",
    "n_plot_neurons=len(plot_neurons)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "for i in range(n_plot_neurons):\n",
    "    plt.subplot(n_plot_neurons,1,i+1)\n",
    "    plt.plot(X[:,i])\n",
    "    plt.plot(Xhat[:,i])\n",
    "    \n",
    "plt.legend(['Actual','Pred'],loc='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare goodness of fit between SCA and PCA model (on the fit data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get: <br> 1) **Reconstruction loss** in the cost function (the weighted sum squared error) <br> 2) **R2 value** of the model (Neurons are weighted by their amount of variance, and sample-weighting is used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For SCA, the reconstruction loss and r2 automatically get assigned to the model after fitting as attributes\n",
    "print('SCA r2:', sca.r2_score)\n",
    "print('SCA reconst_loss:', sca.reconstruction_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For PCA, we use the get_accuracy function from sca.utils\n",
    "[pca_r2_score, pca_reconstruction_loss]=get_accuracy(wpca,X,sample_weights)\n",
    "\n",
    "print('PCA r2:', pca_r2_score)\n",
    "print('PCA reconstr_loss:', pca_reconstruction_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "X_reconstructed = np.dot(ica_latent, ica.mixing_.T) + ica.mean_\n",
    "\n",
    "ica_reconstruction_loss = np.sum((X - X_reconstructed) ** 2)\n",
    "ica_r2_score = r2_score(X,X_reconstructed,sample_weight=sample_weights,multioutput='variance_weighted')\n",
    "\n",
    "print('ICA r2:', ica_r2_score)\n",
    "print('ICA reconstr_loss:', ica_reconstruction_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some other attributes of SCA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Squared neural activity that each latent explains (Note this is slightly different than variance because of the offset term)\n",
    "sca.explained_squared_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters of the model\n",
    "print('n_components:',sca.n_components)\n",
    "print('lam_sparse:',sca.lam_sparse)\n",
    "print('lam_orthog:',sca.lam_orthog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters of the SCA model (commented out below)\n",
    "#See Methods of manuscript for further details on the parameters\n",
    "\n",
    "# sca.params['U']     #Matrix that projects high-d data to low-d space, size [N_neurons , n_components]\n",
    "# sca.params['b_u']   #Offset for low-d space, size [n_components]\n",
    "# sca.params['V']     #Matrix that projects low-d data to high-d space, size [n_components, N]\n",
    "# sca.params['b_v']   #Offset for high-d space, size [N_neurons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdt_env",
   "language": "python",
   "name": "sdt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
